{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caveclient import CAVEclient\n",
    "from intern import array\n",
    "import pickle\n",
    "import numpy as np\n",
    "from agents import data_loader\n",
    "from cloudvolume import CloudVolume\n",
    "from membrane_detection import membranes\n",
    "from agents.scripts import precompute_membrane_vectors, create_post_matrix, merge_paths, get_soma\n",
    "import agents.sensor\n",
    "from agents.run import run_agents\n",
    "import aws.sqs as sqs\n",
    "import sys\n",
    "import time\n",
    "import ast\n",
    "import pandas as pd\n",
    "import agents.scripts as scripts\n",
    "from drive import drive\n",
    "from finding_orphans import *\n",
    "from math import sqrt\n",
    "from tip_finding.tip_finding import tip_finder_decimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_euclidian_distance(proposed_endpoint, gt_endponts_array):\n",
    "    diffs = gt_endponts_array - proposed_endpoint\n",
    "    diffs_distance = np.sqrt(np.sum(np.square(diffs), axis=1))\n",
    "    min_dist_ind = np.argmin(diffs_distance)\n",
    "    min_dist = diffs_distance[min_dist_ind]\n",
    "    return min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpoint_generator(load, invalidation_d, humfrey_iters, decimation_factor):\n",
    "    for idx, i in enumerate(load['seg_id']):\n",
    "        if idx == 2:\n",
    "            break\n",
    "        try:\n",
    "            t1, skel, mesh_obj = tip_finder_decimation(str(i))\n",
    "            endpoints_dict[i] = t1\n",
    "        except:\n",
    "            print(f\"\\n\\nSeg {i} returned error on get. Skipping.\\n\")\n",
    "            pass\n",
    "    load['endpoints'] = load['endpoints'].apply(\n",
    "        lambda x: list(ast.literal_eval(x)))\n",
    "    load['proposed_endpoints'] = load.seg_id.map(endpoints_dict)\n",
    "    return load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_metrics(load, threshold, run, output):\n",
    "    for index, row in load.iterrows():\n",
    "        if index == 2:\n",
    "            break\n",
    "\n",
    "        endpoint_array = np.array(row[\"endpoints\"])\n",
    "        proposed_endpoints_array = np.array(row[\"proposed_endpoints\"])\n",
    "        segID = row[\"seg_id\"]\n",
    "\n",
    "        #skip anything seg_id that isn't 'good'\n",
    "        if row[\"comments\"] != 'good':\n",
    "            print(\"skipping \\n\")\n",
    "            continue\n",
    "\n",
    "        #if both say no endpoints, then it's correct\n",
    "        elif (len(proposed_endpoints_array.shape) == 0 and len(endpoint_array.shape) == 0):\n",
    "            out_df.at[index, 'precision'] = 1.0\n",
    "            out_df.at[index, 'recall'] = 1.0\n",
    "            out_df.at[index, 'f1'] = 1.0\n",
    "\n",
    "            continue\n",
    "\n",
    "        #if we propose no endpoints but there are endpoints, it's wrong\n",
    "        elif (len(proposed_endpoints_array.shape) == 0 and len(endpoint_array.shape) > 0):\n",
    "            out_df.at[index, 'precision'] = 0.0\n",
    "            out_df.at[index, 'recall'] = 0.0\n",
    "            out_df.at[index, 'f1'] = 0.0\n",
    "            continue\n",
    "\n",
    "        #if we propose endpoints but there are none, it's wrong\n",
    "        elif proposed_endpoints_array.size > 0 and endpoint_array.size == 0:\n",
    "            out_df.at[index, 'precision'] = 0.0\n",
    "            out_df.at[index, 'recall'] = 0.0\n",
    "            out_df.at[index, 'f1'] = 0.0\n",
    "            continue\n",
    "\n",
    "        #should skip for now if the endpoint array is size zero to avoid divide by zero error\n",
    "        elif endpoint_array.size == 0:\n",
    "            out_df.at[index, 'precision'] = null\n",
    "            out_df.at[index, 'recall'] = null\n",
    "            out_df.at[index, 'f1'] = null\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            endpoint_ids = np.arange(0, len(endpoint_array))\n",
    "            test_ids = np.arange(\n",
    "                0, len(proposed_endpoints_array)) + len(proposed_endpoints_array)\n",
    "\n",
    "            #get precision and recall at end of each iteration\n",
    "            analysis = run_synapse_analysis(\n",
    "                endpoint_array,\n",
    "                np.array(endpoint_ids),\n",
    "                proposed_endpoints_array,\n",
    "                np.array(test_ids),\n",
    "                threshold,\n",
    "                iso_correction=10,\n",
    "            )\n",
    "\n",
    "            output.loc[len(output.index)] = [run, analysis.precision, analysis.recall, analysis.f1, segID, len(\n",
    "                endpoint_array), endpoint_array, row[\"comments\"], proposed_endpoints_array]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Various utility classes and functions for Confirms.\n",
    "\"\"\"\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "def calculate_precision_recall(tp, fp, fn):\n",
    "    \"\"\"\n",
    "    Calculate precision/recall from given true positives, false positives, and false negatives.\n",
    "    Parameters\n",
    "    ----------\n",
    "    tp : int\n",
    "        The number of true positives.\n",
    "    fp : int\n",
    "        The number of false positives.\n",
    "    fn : int\n",
    "        The number of false negatives.\n",
    "    Returns\n",
    "    -------\n",
    "    precision : float\n",
    "        The precision score.\n",
    "    recall : float\n",
    "        The recall score.\n",
    "    \"\"\"\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def calculate_f1(precision, recall):\n",
    "    \"\"\"\n",
    "    Calculate the F1 score from precision/recall scores.\n",
    "    Parameters\n",
    "    ----------\n",
    "    precision : float\n",
    "        The precision score.\n",
    "    recall : float\n",
    "        The recall score.\n",
    "    Returns\n",
    "    -------\n",
    "    f1 : float\n",
    "        The F1 score.\n",
    "    \"\"\"\n",
    "    return 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "\n",
    "def get_summary_metrics(array):\n",
    "    \"\"\"\n",
    "    Calculate a number of summary metrics on an array of numbers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    array : array_like\n",
    "        Array containing numbers who summary metrics is desired.\n",
    "    Returns\n",
    "    -------\n",
    "    metrics : dict\n",
    "        Dict containing the mean, median, max, min, range, standard deviation,\n",
    "        and variance of the input array.\n",
    "    \"\"\"\n",
    "    summary_object = {}\n",
    "    array = np.array(array)\n",
    "\n",
    "    summary_object[\"mean\"] = np.mean(array)\n",
    "    summary_object[\"median\"] = np.median(array)\n",
    "    summary_object[\"max\"] = np.amax(array)\n",
    "    summary_object[\"min\"] = np.amin(array)\n",
    "    summary_object[\"range\"] = np.mean(array)\n",
    "    summary_object[\"stddev\"] = np.std(array)\n",
    "    summary_object[\"variance\"] = np.var(array)\n",
    "\n",
    "    return summary_object\n",
    "\n",
    "\n",
    "def munkres_assignment(workers, jobs):\n",
    "    \"\"\"\n",
    "    Perform hungarian-munkres assignment.\n",
    "    Parameters\n",
    "    ----------\n",
    "    workers : array_like\n",
    "        Array containing the first set of points.\n",
    "    jobs : array_like\n",
    "        Array containing the second set of points.\n",
    "    Returns\n",
    "    -------\n",
    "    cost_matrix : numpy.ndarray\n",
    "        Matrix containing pairwise distances (the cost of assignment).\n",
    "    row_ind : numpy.ndarray\n",
    "        Row indices of cost_matrix for optimal assignment.\n",
    "    col_ind : numpy.ndarray\n",
    "        Column indices of cost_matrx for optimal assignment.\n",
    "    \"\"\"\n",
    "    cost_matrix = spatial.distance.cdist(workers, jobs, \"euclidean\")\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    return cost_matrix, row_ind, col_ind\n",
    "\n",
    "\n",
    "def make_isotropic(xyz, correction, dimen=2):\n",
    "    \"\"\"\n",
    "    Correct anisotropy in a collection of x, y, z coordinates.\n",
    "    This function performs a deepcopy of xyz before making the necessary modifications.\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyz : numpy.ndarray or pandas.DataFrame:\n",
    "        The coordinate values.\n",
    "    correction : float\n",
    "        The value to correct anisotrophy.\n",
    "    dimen : int\n",
    "        Index of last dimension to which to apply the correction. Default is 2.\n",
    "    Returns\n",
    "    -------\n",
    "    iso_xyz : numpy.ndarray or pandas.DataFrame\n",
    "        An isotropic version of xyz.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(xyz, np.ndarray) and not isinstance(xyz, pd.DataFrame):\n",
    "        xyz = np.asarray(xyz)\n",
    "\n",
    "    shape = np.shape(xyz)\n",
    "    isotropic_xyz = xyz.copy()\n",
    "    size = shape[-1]\n",
    "    if dimen >= size or dimen < 0:\n",
    "        raise ValueError(\n",
    "            \"improper dimen value (valid: 0 through {})\".format(size - 1))\n",
    "    if isinstance(xyz, np.ndarray):\n",
    "        isotropic_xyz[..., dimen] = isotropic_xyz[..., dimen] * correction\n",
    "    else:\n",
    "        isotropic_xyz.iloc[:, dimen] = isotropic_xyz.iloc[:,\n",
    "                                                          dimen] * correction\n",
    "    return isotropic_xyz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Confirms synapse processing and analysis functions.\n",
    "\"\"\"\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# from . import utils\n",
    "# import utils\n",
    "\n",
    "SynapseMetrics = namedtuple(\n",
    "    \"SynapseMetrics\",\n",
    "    [\"precision\", \"recall\", \"f1\", \"tp_gt_ids\", \"tp_test_ids\", \"fp_ids\", \"fn_ids\"],\n",
    ")\n",
    "\n",
    "\n",
    "def filter_synapse_id_core(volume, xyz, ids, box_radius_nm=2500):\n",
    "    \"\"\"\n",
    "    Filter synapses to only return those within a central core.\n",
    "    Parameters\n",
    "    ----------\n",
    "    volume : dict\n",
    "        The volume to filter on.\n",
    "    xyz : array_like\n",
    "        Synapse xyz coordinates.\n",
    "    ids : array_like\n",
    "        Synapse hash (ids).\n",
    "    box_radius_nm : int\n",
    "        radius of cube, from volume core.\n",
    "    Returns\n",
    "    -------\n",
    "        xyz : numpy.ndarray\n",
    "            Synapse coordinates.\n",
    "        ids : numpy.ndarray\n",
    "            Synapse ids.\n",
    "    \"\"\"\n",
    "\n",
    "    xyz_out = []\n",
    "    id_out = []\n",
    "    center = np.asarray(volume[\"center\"], \"float\")\n",
    "    base_resolution = np.asarray(volume[\"base_resolution\"], \"float\")\n",
    "    annotation_resolution = np.asarray(volume[\"resolution\"], \"float\")\n",
    "\n",
    "    pad_vx = box_radius_nm / base_resolution[0] / (2 ** annotation_resolution)\n",
    "    pad_vy = box_radius_nm / base_resolution[1] / (2 ** annotation_resolution)\n",
    "    pad_vz = box_radius_nm / base_resolution[2]\n",
    "    xr = (center[0] - pad_vx, center[0] + pad_vx)\n",
    "    yr = (center[1] - pad_vy, center[1] + pad_vy)\n",
    "    zr = (center[2] - pad_vz, center[2] + pad_vz)\n",
    "\n",
    "    for i in range(len(xyz)):\n",
    "        x = xyz[i][0]\n",
    "        y = xyz[i][1]\n",
    "        z = xyz[i][2]\n",
    "\n",
    "        if (\n",
    "            x > xr[0]\n",
    "            and x < xr[1]\n",
    "            and y > yr[0]\n",
    "            and y < yr[1]\n",
    "            and z > zr[0]\n",
    "            and z < zr[1]\n",
    "        ):\n",
    "            xyz_out.append(xyz[i])\n",
    "            id_out.append(ids[i])\n",
    "\n",
    "    return np.array(xyz_out), np.array(id_out, dtype=np.object)\n",
    "\n",
    "\n",
    "def synapse_match(\n",
    "    xyz_truth, xyz_detect, id_truth, id_detect, thresh\n",
    "):  # pylint: disable=R0914\n",
    "    \"\"\"\n",
    "    <Description here>\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyz_truth : array_like\n",
    "        <description>\n",
    "    xyz_detect : array_like\n",
    "        <description>\n",
    "    id_truth : array_like\n",
    "        <description>\n",
    "    id_detech : array_like\n",
    "        <description>\n",
    "    thresh : float\n",
    "        <description>\n",
    "    Returns\n",
    "    -------\n",
    "    id_lookup : <type>\n",
    "        <description>\n",
    "    \"\"\"\n",
    "\n",
    "    # pylint: disable=C0103\n",
    "\n",
    "    # Ensure we have numpy arrays\n",
    "    xyz_truth = np.asarray(xyz_truth)\n",
    "    xyz_detect = np.asarray(xyz_detect)\n",
    "    id_truth = np.asarray(id_truth)\n",
    "    id_detect = np.asarray(id_detect)\n",
    "\n",
    "    cost, row_ind, col_ind = munkres_assignment(xyz_truth, xyz_detect)\n",
    "    print(cost)\n",
    "    match_idx = np.where(cost[row_ind, col_ind] < thresh)\n",
    "\n",
    "    if len(match_idx) > 0:\n",
    "        # row is idx of GT TP\n",
    "        # col is idx of student TP\n",
    "        gt_tp_idx, det_tp_idx = row_ind[match_idx], col_ind[match_idx]\n",
    "        gt_tp_ids, det_tp_ids = id_truth[gt_tp_idx], id_detect[det_tp_idx]\n",
    "        # Combine into pairs\n",
    "        id_lookup = np.column_stack((gt_tp_ids, det_tp_ids))\n",
    "    else:\n",
    "        gt_tp_idx = []\n",
    "        det_tp_idx = []\n",
    "        id_lookup = np.column_stack(\n",
    "            (np.array([], dtype=\"object\"), np.array([], dtype=\"object\"))\n",
    "        )\n",
    "\n",
    "    # not in row (set diff) are FN\n",
    "    gt_syn_idx = np.arange(0, len(xyz_truth))\n",
    "    fn_idx = np.setdiff1d(gt_syn_idx, gt_tp_idx)\n",
    "    if len(fn_idx) > 0:\n",
    "        fn_ids = id_truth[fn_idx]\n",
    "        id_lookup_fn = np.column_stack((fn_ids, np.repeat(None, len(fn_ids))))\n",
    "        id_lookup = np.concatenate((id_lookup, id_lookup_fn))\n",
    "\n",
    "    # not in col (set diff) are FP\n",
    "    det_syn_idx = set(np.arange(0, len(xyz_detect)))\n",
    "    fp_idx = np.asarray(list(det_syn_idx.difference(det_tp_idx)))\n",
    "    if len(fp_idx) > 0:\n",
    "        fp_ids = id_detect[fp_idx]\n",
    "        id_lookup_fp = np.column_stack((np.repeat(None, len(fp_ids)), fp_ids))\n",
    "        id_lookup = np.concatenate((id_lookup, id_lookup_fp))\n",
    "\n",
    "    return pd.DataFrame(id_lookup, columns=[\"ground_truth\", \"detect\"])\n",
    "\n",
    "\n",
    "def run_synapse_analysis(\n",
    "    gt_xyzs,\n",
    "    gt_ids,\n",
    "    test_xyzs,\n",
    "    test_ids,\n",
    "    threshold,\n",
    "    iso_corrected=False,\n",
    "    iso_correction=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    <Description here>\n",
    "    Parameters\n",
    "    ----------\n",
    "    gt_xyzs : numpy.ndarray\n",
    "        Array of ground truth xyz coordinates\n",
    "    gt_ids : numpy.ndarray\n",
    "        Array of ids associated with ground truth xyz coordinates\n",
    "    test_xyzs : numpy.ndarray\n",
    "        Array of test xyz coordinates\n",
    "    test_ids : numpy.ndarray\n",
    "        Array of ids associated with test xyz coordinates\n",
    "    threshold : float\n",
    "        Synapse matching threshold\n",
    "    iso_corrected : boolean\n",
    "        Mark whether the data is isotropic. If not, it will be made isotropic using the\n",
    "        `iso_correction` parameter.\n",
    "    iso_correction : float\n",
    "        Value to correct anistropy.\n",
    "    Returns\n",
    "    -------\n",
    "    sm : SynapseMetrics\n",
    "        Resultant object containing precision, recall, and F1 scores, along with\n",
    "        with true positive (both ground truth and test), false positive, and false negative\n",
    "        ids.\n",
    "    \"\"\"\n",
    "    # pylint: disable=R0913,R0914\n",
    "    if not iso_corrected:\n",
    "        # gt_xyzs = utils.make_isotropic(gt_xyzs, iso_correction)\n",
    "        gt_xyzs = make_isotropic(gt_xyzs, iso_correction)\n",
    "        # test_xyzs = utils.make_isotropic(test_xyzs, iso_correction)\n",
    "        test_xyzs = make_isotropic(test_xyzs, iso_correction)\n",
    "\n",
    "    results_table = synapse_match(\n",
    "        gt_xyzs, test_xyzs, gt_ids, test_ids, threshold)\n",
    "\n",
    "    tp = results_table.dropna()\n",
    "    fn = results_table[results_table.detect.isnull()]\n",
    "    fp = results_table[results_table.ground_truth.isnull()]\n",
    "\n",
    "    assert len(tp.ground_truth) == len(\n",
    "        tp.detect\n",
    "    ), \"true positive ground truth and test size mismatch\"\n",
    "\n",
    "    tp_count = len(tp)\n",
    "    fp_count = len(fp)\n",
    "    fn_count = len(fn)\n",
    "\n",
    "    try:\n",
    "        # precision, recall = utils.calculate_precision_recall(\n",
    "        #     tp_count, fp_count, fn_count\n",
    "        # )\n",
    "\n",
    "        precision, recall = calculate_precision_recall(\n",
    "            tp_count, fp_count, fn_count\n",
    "        )\n",
    "\n",
    "    except ZeroDivisionError:\n",
    "        precision, recall = np.nan, np.nan\n",
    "\n",
    "    try:\n",
    "        # f1 = utils.calculate_f1(precision, recall)\n",
    "        f1 = calculate_f1(precision, recall)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = np.nan\n",
    "\n",
    "    sm = SynapseMetrics(\n",
    "        precision=precision,\n",
    "        recall=recall,\n",
    "        f1=f1,\n",
    "        tp_gt_ids=np.asarray(tp.ground_truth),\n",
    "        tp_test_ids=np.asarray(tp.detect),\n",
    "        fp_ids=np.asarray(fp.detect),\n",
    "        fn_ids=np.asarray(fn.ground_truth),\n",
    "    )\n",
    "    return sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in data\n",
    "load = pd.read_csv(\"agents/Data/endpoints_gt5.csv\")\n",
    "endpoints_dict = {}\n",
    "\n",
    "# #creating series objects for the desired collumns\n",
    "# segIDs = load['seg_id']\n",
    "# Endpoints = load['endpoints']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate out_df\n",
    "\n",
    "out_df = pd.DataFrame(columns=[\"run\", \"precision\", \"recall\", \"f1\", \"seg_id\",\n",
    "                      \"num_endpoints\", \"endpoints\", \"comments\", \"proposed_endpoints\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/28/2022 04:01:05 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3996/3996 [00:00<00:00, 293147.91it/s]\n",
      "07/28/2022 04:01:07 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10649 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/meshparty/skeletonize.py:613: RuntimeWarning: invalid value encountered in multiply\n",
      "  target = np.nanargmax(root_ds * valid)\n",
      "100%|██████████| 10649/10649 [00:00<00:00, 485960.80it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  99.46356117 4423.90008929]\n",
      " [4415.78452826   24.37211521]]\n",
      "[[ 146.85366866 5470.51569781 9272.57704201]\n",
      " [5554.85157317  495.77414213 8350.73439884]\n",
      " [9231.09576378 8664.4402589   368.27978495]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/28/2022 04:01:10 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3996/3996 [00:00<00:00, 401332.28it/s]\n",
      "07/28/2022 04:01:12 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10649 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/meshparty/skeletonize.py:613: RuntimeWarning: invalid value encountered in multiply\n",
      "  target = np.nanargmax(root_ds * valid)\n",
      "100%|██████████| 10649/10649 [00:00<00:00, 491527.93it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  99.46356117 4423.90008929]\n",
      " [4415.78452826   24.37211521]]\n",
      "[[ 146.85366866 5470.51569781 9272.57704201]\n",
      " [5554.85157317  495.77414213 8350.73439884]\n",
      " [9231.09576378 8664.4402589   368.27978495]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/28/2022 04:01:14 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3996/3996 [00:00<00:00, 635105.68it/s]\n",
      "07/28/2022 04:01:16 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10649 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/meshparty/skeletonize.py:613: RuntimeWarning: invalid value encountered in multiply\n",
      "  target = np.nanargmax(root_ds * valid)\n",
      "100%|██████████| 10649/10649 [00:00<00:00, 518006.88it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  99.46356117 4423.90008929]\n",
      " [4415.78452826   24.37211521]]\n",
      "[[ 146.85366866 5470.51569781 9272.57704201]\n",
      " [5554.85157317  495.77414213 8350.73439884]\n",
      " [9231.09576378 8664.4402589   368.27978495]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/28/2022 04:01:19 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3996/3996 [00:00<00:00, 536591.61it/s]\n",
      "07/28/2022 04:01:23 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10649 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/meshparty/skeletonize.py:613: RuntimeWarning: invalid value encountered in multiply\n",
      "  target = np.nanargmax(root_ds * valid)\n",
      "100%|██████████| 10649/10649 [00:00<00:00, 446705.04it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  99.46356117 4423.90008929]\n",
      " [4415.78452826   24.37211521]]\n",
      "[[ 146.85366866 5470.51569781 9272.57704201]\n",
      " [5554.85157317  495.77414213 8350.73439884]\n",
      " [9231.09576378 8664.4402589   368.27978495]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/28/2022 04:01:25 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3996/3996 [00:00<00:00, 493041.09it/s]\n",
      "07/28/2022 04:01:28 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10649 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/meshparty/skeletonize.py:613: RuntimeWarning: invalid value encountered in multiply\n",
      "  target = np.nanargmax(root_ds * valid)\n",
      "100%|██████████| 10649/10649 [00:00<00:00, 519229.31it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  99.46356117 4423.90008929]\n",
      " [4415.78452826   24.37211521]]\n",
      "[[ 146.85366866 5470.51569781 9272.57704201]\n",
      " [5554.85157317  495.77414213 8350.73439884]\n",
      " [9231.09576378 8664.4402589   368.27978495]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/28/2022 04:01:29 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3996/3996 [00:00<00:00, 714730.86it/s]\n",
      "07/28/2022 04:01:32 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10649 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/meshparty/skeletonize.py:613: RuntimeWarning: invalid value encountered in multiply\n",
      "  target = np.nanargmax(root_ds * valid)\n",
      "100%|██████████| 10649/10649 [00:00<00:00, 343414.24it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  99.46356117 4423.90008929]\n",
      " [4415.78452826   24.37211521]]\n",
      "[[ 146.85366866 5470.51569781 9272.57704201]\n",
      " [5554.85157317  495.77414213 8350.73439884]\n",
      " [9231.09576378 8664.4402589   368.27978495]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/28/2022 04:01:34 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3996/3996 [00:00<00:00, 536540.07it/s]\n",
      "07/28/2022 04:01:36 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10649 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/meshparty/skeletonize.py:613: RuntimeWarning: invalid value encountered in multiply\n",
      "  target = np.nanargmax(root_ds * valid)\n",
      "100%|██████████| 10649/10649 [00:00<00:00, 509812.05it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  99.46356117 4423.90008929]\n",
      " [4415.78452826   24.37211521]]\n",
      "[[ 146.85366866 5470.51569781 9272.57704201]\n",
      " [5554.85157317  495.77414213 8350.73439884]\n",
      " [9231.09576378 8664.4402589   368.27978495]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/28/2022 04:01:38 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3996/3996 [00:00<00:00, 610914.48it/s]\n",
      "07/28/2022 04:01:40 PM WARNING: face_normals incorrect shape, ignoring! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10649 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/meshparty/skeletonize.py:613: RuntimeWarning: invalid value encountered in multiply\n",
      "  target = np.nanargmax(root_ds * valid)\n",
      "100%|██████████| 10649/10649 [00:00<00:00, 492693.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  99.46356117 4423.90008929]\n",
      " [4415.78452826   24.37211521]]\n",
      "[[ 146.85366866 5470.51569781 9272.57704201]\n",
      " [5554.85157317  495.77414213 8350.73439884]\n",
      " [9231.09576378 8664.4402589   368.27978495]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    }
   ],
   "source": [
    "run = 0\n",
    "# for invalidation_d in range(4000, 6001, 200):\n",
    "for invalidation_d in range(4000, 4201, 200):\n",
    "    # for num_humfrey_iters in range(0,251,25):\n",
    "    for num_humfrey_iters in range(50, 76, 25):\n",
    "        # for decimation_factor in np.arange(0.3, 0.71, 0.04):\n",
    "        for decimation_factor in np.linspace(0.3, 0.35, num = 2):\n",
    "            load = pd.read_csv(\"agents/Data/endpoints_gt5.csv\") #NOT THE BEST WAY TO DO THIS!!!\n",
    "            run += 1\n",
    "            load_with_proposed_endpoints = endpoint_generator(\n",
    "                load, invalidation_d=invalidation_d, humfrey_iters=num_humfrey_iters, decimation_factor=decimation_factor)\n",
    "            out_df = testing_metrics(\n",
    "                load_with_proposed_endpoints, threshold=500, run=run, output=out_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>seg_id</th>\n",
       "      <th>num_endpoints</th>\n",
       "      <th>endpoints</th>\n",
       "      <th>comments</th>\n",
       "      <th>proposed_endpoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.646911e+17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[[402584, 228856, 23991], [402985, 229235, 235...</td>\n",
       "      <td>good</td>\n",
       "      <td>[[402567, 228758, 23991], [402990, 229222, 235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.646911e+17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[401612, 224623, 23991], [405257, 226318, 236...</td>\n",
       "      <td>good</td>\n",
       "      <td>[[401467, 224644, 23990], [405021, 226754, 236...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.646911e+17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[401612, 224623, 23991], [405257, 226318, 236...</td>\n",
       "      <td>good</td>\n",
       "      <td>[[401467, 224644, 23990], [405021, 226754, 236...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  precision  recall   f1        seg_id  num_endpoints  \\\n",
       "0   1.0        1.0     1.0  1.0  8.646911e+17            2.0   \n",
       "1   1.0        1.0     1.0  1.0  8.646911e+17            3.0   \n",
       "4   NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "5   NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "6   NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "7   NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "9   NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "10  NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "11  NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "12  NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "13  NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "14  NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "15  NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "16  8.0        1.0     1.0  1.0  8.646911e+17            3.0   \n",
       "18  NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "19  NaN        0.0     0.0  0.0           NaN            NaN   \n",
       "\n",
       "                                            endpoints comments  \\\n",
       "0   [[402584, 228856, 23991], [402985, 229235, 235...     good   \n",
       "1   [[401612, 224623, 23991], [405257, 226318, 236...     good   \n",
       "4                                                 NaN      NaN   \n",
       "5                                                 NaN      NaN   \n",
       "6                                                 NaN      NaN   \n",
       "7                                                 NaN      NaN   \n",
       "9                                                 NaN      NaN   \n",
       "10                                                NaN      NaN   \n",
       "11                                                NaN      NaN   \n",
       "12                                                NaN      NaN   \n",
       "13                                                NaN      NaN   \n",
       "14                                                NaN      NaN   \n",
       "15                                                NaN      NaN   \n",
       "16  [[401612, 224623, 23991], [405257, 226318, 236...     good   \n",
       "18                                                NaN      NaN   \n",
       "19                                                NaN      NaN   \n",
       "\n",
       "                                   proposed_endpoints  \n",
       "0   [[402567, 228758, 23991], [402990, 229222, 235...  \n",
       "1   [[401467, 224644, 23990], [405021, 226754, 236...  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16  [[401467, 224644, 23990], [405021, 226754, 236...  \n",
       "18                                                NaN  \n",
       "19                                                NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
