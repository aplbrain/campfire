{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "from meshparty import skeletonize, trimesh_io\n",
    "from caveclient import CAVEclient\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import datetime\n",
    "import networkx as nx\n",
    "from scipy.sparse import identity\n",
    "from scipy.spatial import distance_matrix\n",
    "import scipy \n",
    "from tqdm import tqdm\n",
    "# import aws\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pyembree\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial as spatial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATAFRAME FOR NEURONS AND ORPHANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/sheeltanna/Desktop/AGT_REPO/campfire/tip_finding/Orphans.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m orphans \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/sheeltanna/Desktop/AGT_REPO/campfire/tip_finding/Orphans.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(orphans)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/sheeltanna/Desktop/AGT_REPO/campfire/tip_finding/Orphans.csv'"
     ]
    }
   ],
   "source": [
    "orphans = pd.read_csv(\"/Users/sheeltanna/Desktop/AGT_REPO/campfire/tip_finding/Orphans.csv\")\n",
    "print(orphans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = pd.read_csv(\"/Users/sheeltanna/Desktop/AGT_REPO/campfire/tip_finding/Neuron.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_array(x):\n",
    "    res = list(map(str.strip, x.split('; ')))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 seg_id  num_endpoints  \\\n",
      "0    864691135909994000              2   \n",
      "1    864691135247440303              3   \n",
      "2    864691134794123793              2   \n",
      "3    864691135772363453              7   \n",
      "4    864691135314714227              2   \n",
      "..                  ...            ...   \n",
      "127  864691135319600870              2   \n",
      "128  864691136558839249              2   \n",
      "129  864691135012763638             -1   \n",
      "130  864691135458639120              2   \n",
      "131  864691135826764827              2   \n",
      "\n",
      "                                             endpoints  \n",
      "0    [(402584, 228856, 23991), (402985, 229235, 235...  \n",
      "1    [(401612, 224623, 23991), (405257, 226318, 236...  \n",
      "2    [(401242, 228382, 24444), (400982, 228457, 245...  \n",
      "3    [(401289, 218721, 23991), (399895, 216533, 235...  \n",
      "4    [(397867, 232230, 23999), (397854, 232252, 239...  \n",
      "..                                                 ...  \n",
      "127   [(106608, 111803, 20796), (98290, 97555, 21045)]  \n",
      "128  [(103138, 188530, 21200), (91780, 189141, 20879)]  \n",
      "129                                               [()]  \n",
      "130  [(127475, 206611, 21525), (128120, 207267, 215...  \n",
      "131  [(122293, 186204, 19621), (124943, 185661, 186...  \n",
      "\n",
      "[132 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "orphans['endpoints'] = orphans['endpoints'].map(lambda x: list(map(str.strip, x.split('; '))))\n",
    "print(orphans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Neurons  num_endpoints  \\\n",
      "0   864691136577830164              6   \n",
      "1   864691135683615218             13   \n",
      "2   864691135864989916              2   \n",
      "3   864691135837578899              9   \n",
      "4   864691135501859650             14   \n",
      "5   864691135544674088              7   \n",
      "6   864691135614368971             12   \n",
      "7   864691135334773481              7   \n",
      "8   864691135614361291             12   \n",
      "9   864691135445907602             12   \n",
      "10  864691136390697343              8   \n",
      "11  864691135396741921              9   \n",
      "12  864691135360418631              6   \n",
      "13  864691135463797061              6   \n",
      "14  864691135526309723              9   \n",
      "\n",
      "                                            endpoints  \n",
      "0   [(402188, 228684, 24029), (401258, 224832, 240...  \n",
      "1   [(77233, 113188, 20454), (100382, 143836, 2164...  \n",
      "2   [(211973, 200313, 23233), (167751, 211623, 207...  \n",
      "3   [(351264, 143646, 15182), (344801, 142291, 169...  \n",
      "4   [(101840, 247377, 19543), (92823, 255328, 2038...  \n",
      "5   [(220484, 239044, 20481), (238449, 242308, 224...  \n",
      "6   [(107820, 233757, 21960), (116372, 239008, 232...  \n",
      "7   [(138311, 218409, 26379), (114789, 194406, 242...  \n",
      "8   [(123240, 178472, 21529), (121863, 182085, 215...  \n",
      "9   [(293401, 150411, 19104), (313432, 160982, 185...  \n",
      "10  [(142469, 252585, 22976), (114049, 233747, 220...  \n",
      "11  [(346513, 82659, 27098), (361886, 82055, 27634...  \n",
      "12  [(110598, 239837, 22040), (108642, 243230, 219...  \n",
      "13  [(103052, 175611, 18430), (104081, 174998, 184...  \n",
      "14  [(108958, 194091, 22035), (107125, 175763, 219...  \n"
     ]
    }
   ],
   "source": [
    "neurons['endpoints'] = neurons['endpoints'].map(lambda x: list(map(str.strip, x.split('; '))))\n",
    "print(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402584, 228856, 23991)\n",
      "(402985, 229235, 23554)\n",
      "(401612, 224623, 23991)\n",
      "(405257, 226318, 23620)\n",
      "(409162, 219642, 23891)\n",
      "(401242, 228382, 24444)\n",
      "(400982, 228457, 24513)\n",
      "(401289, 218721, 23991)\n",
      "(399895, 216533, 23526)\n",
      "(406366, 215719, 23621)\n",
      "(403940, 210639, 23991)\n",
      "(394569, 213255, 23991)\n",
      "(376682, 175983, 22020)\n",
      "(365111, 191189, 24020)\n",
      "(371210, 191781, 21770)\n",
      "(397867, 232230, 23999)\n",
      "(397854, 232252, 23997)\n",
      "(403332, 227545, 24398)\n",
      "(403566, 227614, 24425)\n",
      "(77262, 113088, 20442),\n",
      "(79178, 109116, 20402)\n",
      "(100475, 143982, 21654)\n",
      "(100583, 144194, 21702)\n",
      "(80890, 147158, 20708)\n",
      "(81592, 148549, 20453)\n",
      "(81373, 148139, 20453)\n",
      "(83362, 154016, 20454)\n",
      "(83471, 163193, 20640)\n",
      "(71898, 146194, 20442)\n",
      "(71499, 146291, 20404)\n",
      "(78610, 145071, 20707)\n",
      "(75884, 143590, 20453)\n",
      "(78226, 151636, 19714)\n",
      "(66549, 151567, 19790)\n",
      "(78090, 150130, 20388)\n",
      "(77575, 107807, 21133)\n",
      "(77000, 99565, 21215)\n",
      "(79785, 135709, 21133)\n",
      "(84176, 127514, 21582)\n",
      "(80523, 134733, 21498)\n",
      "(81198, 106660, 21133)\n",
      "(88864, 99498, 20482)\n",
      "(77826, 139204, 21137)\n",
      "(77790, 139215, 21140)\n",
      "(79165, 133413, 20708)\n",
      "(79077, 133479, 20677)\n",
      "(75409, 116393, 21135)\n",
      "(74841, 116076, 21217)\n",
      "(82311, 143111, 20720)\n",
      "(84508, 142994, 20724)\n",
      "(84551, 142973, 20722)\n",
      "(212020, 200330, 23231)\n",
      "(212535, 200478, 23228)\n",
      "(167695, 211664, 20725)\n",
      "(145921, 225039, 22976)\n",
      "(351150, 143681, 15176)\n",
      "(348147, 144970, 14850)\n",
      "(344600, 142349, 16939)\n",
      "(344592, 142335, 16937)\n",
      "(365649, 143596, 17209)\n",
      "(365939, 143556, 17266)\n",
      "(366719, 138890, 16417)\n",
      "(367885, 138975, 16518)\n",
      "(353411, 147608, 15177)\n",
      "(352169, 149000, 14848)\n",
      "(363998, 136280, 16225)\n",
      "(364022, 136258, 16224)\n",
      "(366292, 145971, 16282)\n",
      "(365559, 146710, 16237)\n",
      "(366729, 146323, 16252)\n",
      "(364450, 138585, 16225)\n",
      "(364459, 138583, 16224)\n",
      "(368040, 143694, 16594)\n",
      "(369126, 143559, 16661)\n",
      "(101795, 247367, 19549)\n",
      "(97049, 240061, 20592)\n",
      "(92574, 255351, 20402)\n",
      "(92241, 255519, 20432)\n",
      "(114532, 262237, 21456)\n",
      "(117327, 266080, 21565)\n",
      "(121332, 261988, 21081)\n",
      "(124363, 266598, 21292)\n",
      "(124076, 245911, 20653)\n",
      "(131332, 245544, 20993)\n",
      "(91990, 254558, 18886)\n",
      "(89162, 254502, 18809)\n",
      "(91998, 257005, 18030)\n",
      "(92047, 257166, 17971)\n",
      "(95465, 260435, 18180)\n",
      "(103494, 249888, 18886)\n",
      "(95051, 235495, 18680)\n",
      "(89795, 241829, 19735)\n",
      "(92006, 236451, 19553)\n",
      "(83827, 237824, 19706)\n",
      "(83818, 240029, 19685)\n",
      "(79493, 232299, 19806)\n",
      "(92375, 244828, 19552)\n",
      "(89922, 247651, 20068)\n",
      "(99421, 237973, 18886)\n",
      "(118801, 231687, 18346)\n",
      "(99834, 231257, 18886)\n",
      "(83955, 228517, 18160)\n",
      "(101885, 213030, 17722)\n",
      "(95893, 197762, 16390)\n",
      "(83218, 198424, 17497)\n",
      "(103084, 242200, 18886)\n",
      "(110692, 237219, 18434)\n",
      "(111502, 242338, 18430)\n",
      "(101395, 241109, 18886)\n",
      "(95743, 240134, 17874)\n",
      "(88413, 241445, 18707)\n",
      "(108790, 257101, 19282)\n",
      "(124559, 269371, 19408)\n",
      "()\n",
      "(238371, 242473, 22476)\n",
      "(238457, 244555, 22569)\n",
      "(244655, 242054, 22367)\n",
      "()\n",
      "(214003, 239696, 22150)\n",
      "(207975, 242223, 21811)\n",
      "(207392, 247744, 21826)\n",
      "(229738, 242657, 23002)\n",
      "(232273, 221019, 24296)\n",
      "(221936, 234388, 22049)\n",
      "(225075, 238155, 19382)\n",
      "(225894, 221672, 22439)\n",
      "(211405, 208983, 22094)\n",
      "(216657, 214363, 20269)\n",
      "(219251, 215626, 21774)\n",
      "(218205, 197895, 20556)\n",
      "(248614, 184604, 22874)\n",
      "(237999, 180993, 23196)\n",
      "(203332, 186364, 22843)\n",
      "(216400, 168757, 20654)\n",
      "(215980, 250188, 22175)\n",
      "(216934, 252017, 21871)\n",
      "(107780, 233751, 21951)\n",
      "(102886, 233653, 21793)\n",
      "(101029, 231512, 21571)\n",
      "(116397, 239042, 23272)\n",
      "(116122, 242018, 23658)\n",
      "(128574, 244535, 23440)\n",
      "(124127, 246567, 21658)\n",
      "(125186, 247739, 21278)\n",
      "(124451, 234883, 21742)\n",
      "(136200, 231009, 21675)\n",
      "(137726, 231340, 21467)\n",
      "(115538, 236798, 23272)\n",
      "(119437, 236091, 24379)\n",
      "(105962, 225371, 22049)\n",
      "(105764, 225119, 22040)\n",
      "(106751, 240190, 22672)\n",
      "(105119, 240360, 22705)\n",
      "(111507, 222732, 22035)\n",
      "(103133, 218005, 21203)\n",
      "(102041, 153623, 21675)\n",
      "(112350, 146522, 21642)\n",
      "(99727, 149747, 20928)\n",
      "(92904, 105009, 21852)\n",
      "(98126, 159248, 21078)\n",
      "(95362, 152436, 20927)\n",
      "(122297, 236006, 21160)\n",
      "(122269, 235695, 21274)\n",
      "(122185, 236026, 21200)\n",
      "(110710, 238814, 22885)\n",
      "(108984, 238250, 23105)\n",
      "(109103, 239918, 23104)\n",
      "(114302, 226209, 22036)\n",
      "(122799, 224013, 21841)\n",
      "(108331, 239439, 22553)\n",
      "(108001, 239551, 22547)\n",
      "(138540, 218696, 26348)\n",
      "(113372, 224291, 24259)\n",
      "(114948, 194594, 24243)\n",
      "(111880, 193451, 24003)\n",
      "(124463, 104387, 26580)\n",
      "(119649, 95511, 26587)\n",
      "(139122, 211601, 27166)\n",
      "(139135, 211585, 27170)\n",
      "(138830, 217418, 26348)\n",
      "(119661, 181314, 25228)\n",
      "(139743, 217650, 26348)\n",
      "(164292, 216295, 23395)\n",
      "(128688, 164321, 26262)\n",
      "(122720, 160983, 25666)\n",
      "(119788, 145710, 25344)\n",
      "(123195, 178592, 21507)\n",
      "(122128, 178347, 21278)\n",
      "(121982, 182250, 21512)\n",
      "(120362, 183485, 21278)\n",
      "(121355, 183816, 21279)\n",
      "(122898, 181913, 21279)\n",
      "(124468, 181794, 21280)\n",
      "(117392, 179577, 20651)\n",
      "(103241, 168587, 21422)\n",
      "(120495, 185235, 21512)\n",
      "(120221, 188999, 20922)\n",
      "(128136, 182787, 21520)\n",
      "(131324, 185441, 20778)\n",
      "(126152, 175708, 21515)\n",
      "(124992, 176063, 21277)\n",
      "(141422, 170976, 21715)\n",
      "(144545, 167108, 21467)\n",
      "(144234, 161388, 22553)\n",
      "(136079, 182458, 20917)\n",
      "(136402, 182192, 20846)\n",
      "(125651, 179253, 21829)\n",
      "(134788, 162962, 23513)\n",
      "(127745, 180987, 21829)\n",
      "(127799, 168227, 22142)\n",
      "(145826, 168883, 22019)\n",
      "(122541, 156621, 23215)\n",
      "(123400, 153233, 23659)\n",
      "(105079, 184428, 21958)\n",
      "(101985, 184289, 22036)\n",
      "()\n",
      "(124325, 184170, 21779)\n",
      "(124064, 184357, 21809)\n",
      "()\n",
      "(313505, 161103, 18580)\n",
      "(314477, 162881, 18717)\n",
      "(307899, 98712, 19067)\n",
      "(309700, 87653, 19669)\n",
      "(286807, 94503, 18046)\n",
      "(291939, 86875, 18287)\n",
      "(286266, 89000, 18566)\n",
      "(299555, 102903, 17377)\n",
      "(299986, 100770, 17256)\n",
      "(280639, 88256, 18965)\n",
      "(280377, 87163, 19077)\n",
      "(299386, 144111, 17853)\n",
      "(308152, 142095, 17214)\n",
      "(273490, 135822, 19621)\n",
      "(273461, 135845, 19600)\n",
      "(283057, 132640, 16711)\n",
      "(282934, 132656, 16737)\n",
      "(291603, 151786, 16467)\n",
      "(290050, 150005, 15752)\n",
      "(290423, 152780, 15746)\n",
      "(300397, 94652, 17399)\n",
      "(303732, 84897, 16745)\n",
      "(284058, 92219, 17275)\n",
      "(280477, 80185, 16526)\n",
      "(142439, 252626, 22975)\n",
      "(144188, 253104, 22654)\n",
      "(114021, 233743, 22040)\n",
      "(112548, 233575, 22682)\n",
      "(133389, 255584, 22054)\n",
      "(133595, 255928, 22130)\n",
      "(119057, 255814, 24248)\n",
      "(120636, 255518, 25187)\n",
      "(110778, 257333, 22958)\n",
      "(115300, 229294, 20749)\n",
      "(89806, 185302, 20453)\n",
      "(91679, 127944, 19550)\n",
      "()\n",
      "(127036, 252594, 22227)\n",
      "(142688, 236562, 22581)\n",
      "(346497, 82778, 27090)\n",
      "(339051, 74578, 26769)\n",
      "(339905, 90093, 27016)\n",
      "(362020, 82097, 27644)\n",
      "(362087, 82108, 27649)\n",
      "(351839, 91058, 27284)\n",
      "(349567, 97065, 26976)\n",
      "(356329, 81030, 27146)\n",
      "(356347, 81004, 27144)\n",
      "(357525, 81584, 25828)\n",
      "(358640, 81180, 25734)\n",
      "(351987, 86221, 25848)\n",
      "(352110, 86192, 25831)\n",
      "(347271, 87374, 25828)\n",
      "(347862, 89018, 24930)\n",
      "(3345353475, 78900, 27433)\n",
      "(353483, 78877, 27430)\n",
      "(350303, 87245, 25848)\n",
      "(352494, 73961, 24070)\n",
      "(361312, 78217, 23289)\n",
      "(355414, 99032, 24187)\n",
      "(362931, 90693, 23843)\n",
      "(369298, 84988, 24004)\n",
      "(363628, 84718, 23270)\n",
      "(359997, 79012, 22863)\n",
      "(363894, 77910, 22917)\n",
      "(368113, 80177, 22869)\n",
      "()\n",
      "(108698, 243200, 21973)\n",
      "(108707, 243206, 21960)\n",
      "(109971, 248988, 22943)\n",
      "(109861, 248990, 22952)\n",
      "(128700, 257839, 21398)\n",
      "(129082, 258007, 21381)\n",
      "(111700, 241689, 22797)\n",
      "(110188, 241117, 22872)\n",
      "(116186, 247468, 23275)\n",
      "(114619, 246629, 23503)\n",
      "(103037, 175591, 18434)\n",
      "(99978, 172371, 18836)\n",
      "(104045, 175065, 18434)\n",
      "(104250, 162713, 19999)\n",
      "(84884, 179330, 16386)\n",
      "(84548, 179822, 16236)\n",
      "(125649, 172835, 17141)\n",
      "(125655, 172900, 17179)\n",
      "(104286, 187511, 18434)\n",
      "(108856, 189773, 20406)\n",
      "(103922, 176481, 18434)\n",
      "(100014, 169299, 19066)\n",
      "(108881, 194031, 22039)\n",
      "(110659, 191115, 23047)\n",
      "(100252, 195857, 22499)\n",
      "(106626, 175281, 21972)\n",
      "(106601, 175281, 21974)\n",
      "(116389, 195392, 19326)\n",
      "(121899, 191082, 17880)\n",
      "(122789, 154701, 20649)\n",
      "(122688, 151314, 20558)\n",
      "(106608, 111803, 20796)\n",
      "(98290, 97555, 21045)\n",
      "(103138, 188530, 21200)\n",
      "(91780, 189141, 20879)\n",
      "()\n",
      "(127475, 206611, 21525)\n",
      "(128120, 207267, 21512)\n",
      "(122293, 186204, 19621)\n",
      "(124943, 185661, 18677)\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "for index, row in orphans.iterrows():\n",
    "     for endpoint in row[\"endpoints\"]:\n",
    "         print(endpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS FOR TIP FINDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_process_mesh(root_id):\n",
    "    datastack_name = \"minnie65_phase3_v1\"\n",
    "    client = CAVEclient(datastack_name)\n",
    "    vol = CloudVolume(\n",
    "        client.info.segmentation_source(),\n",
    "        use_https=True,\n",
    "        progress=False,\n",
    "        bounded=False,\n",
    "        fill_missing=True,\n",
    "        secrets={\"token\": client.auth.token}\n",
    "    )\n",
    "    print(\"Downloading Mesh\")\n",
    "    mesh = vol.mesh.get(str(root_id))[root_id]\n",
    "    mesh_obj = trimesh.Trimesh(np.divide(mesh.vertices, np.array([1,1,1])), mesh.faces)\n",
    "    print(\"Vertices: \", mesh.vertices.shape[0])\n",
    "\n",
    "    if mesh_obj.volume > 4000000000000:\n",
    "        print(\"TOO BIG, SKIPPING\")\n",
    "        #queue_url_endpoints = sqs.get_or_create_queue(\"root_ids_functional_dlqueue\")\n",
    "\n",
    "        #entries=sqs.construct_rootid_entries([root_id])\n",
    "\n",
    "        #sqs.send_batch(queue_url_endpoints, entries)\n",
    "\n",
    "        return None\n",
    "    trimesh.repair.fix_normals(mesh_obj)\n",
    "    mesh_obj.fill_holes()\n",
    "\n",
    "    return mesh_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soma(soma_id:str):\n",
    "    cave_client = CAVEclient('minnie65_phase3_v1')\n",
    "    soma = cave_client.materialize.query_table(\n",
    "        \"nucleus_neuron_svm\",\n",
    "        filter_equal_dict={'id':soma_id}\n",
    "    )\n",
    "    return soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mesh_ccs(mesh_obj):\n",
    "    print(\"Processing CC's\")\n",
    "    ccs_graph = trimesh.graph.connected_components(mesh_obj.edges)\n",
    "    ccs_len = [len(c) for c in ccs_graph]\n",
    "\n",
    "    # Subselect the parts of the mesh that are not inside one another \n",
    "    # the other components are an artifact of the soma seg and small unfilled sections\n",
    "    largest_component = ccs_graph[np.argmax(ccs_len)]\n",
    "    largest_component_remap = np.arange(ccs_graph[np.argmax(ccs_len)].shape[0])\n",
    "    face_dict = {largest_component[i]:largest_component_remap[i] for i in range(largest_component.shape[0])}\n",
    "\n",
    "    new_faces_mask = np.isin(mesh_obj.faces, list(face_dict.keys()))\n",
    "    new_faces_mask = new_faces_mask[:, 0]*new_faces_mask[:, 1]*new_faces_mask[:, 2]\n",
    "\n",
    "    new_faces = np.vectorize(face_dict.get)(mesh_obj.faces[new_faces_mask])\n",
    "    new_faces = new_faces[new_faces[:, 0] != None]\n",
    "    largest_component_mesh = trimesh.Trimesh(mesh_obj.vertices[largest_component], new_faces)\n",
    "\n",
    "    all_ids = set(largest_component)\n",
    "    encapsulated_ids = []\n",
    "\n",
    "    for i in range(1, len(ccs_graph)):\n",
    "        n_con = largest_component_mesh.contains(mesh_obj.vertices[ccs_graph[i]])\n",
    "        if np.sum(n_con) / n_con.shape[0] == 0 and n_con.shape[0] > 50:\n",
    "            all_ids.update(ccs_graph[i])\n",
    "        else:\n",
    "            if len(ccs_graph[i]) < 1000:\n",
    "                encapsulated_ids.append((np.mean(mesh_obj.vertices[ccs_graph[i]], axis=0)/[4,4,40], len(ccs_graph[i])))\n",
    "            \n",
    "    all_component = np.array(list(ccs_graph[np.argmax(ccs_len)]))\n",
    "    all_component_remap = np.arange(all_component.shape[0])\n",
    "    face_dict = {all_component[i]:all_component_remap[i] for i in range(all_component.shape[0])}\n",
    "    new_faces_mask = np.isin(mesh_obj.faces, list(face_dict.keys()))\n",
    "    new_faces_mask = new_faces_mask[:, 0]*new_faces_mask[:, 1]*new_faces_mask[:, 2]\n",
    "\n",
    "    new_faces = np.vectorize(face_dict.get)(mesh_obj.faces[new_faces_mask])\n",
    "    new_faces[new_faces[:, 0] != None]\n",
    "    \n",
    "    largest_component_mesh = trimesh.Trimesh(mesh_obj.vertices[all_component], new_faces)\n",
    "\n",
    "    mesh_obj = largest_component_mesh\n",
    "    return mesh_obj, encapsulated_ids, np.max(ccs_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_defects(mesh_obj, a=.75):\n",
    "    bad_edges = trimesh.grouping.group_rows(\n",
    "        mesh_obj.edges_sorted, require_count=1)\n",
    "    bad_edges_ind = mesh_obj.edges[bad_edges]\n",
    "    sparse_edges = mesh_obj.edges_sparse\n",
    "    xs = list(bad_edges_ind[:, 0]) + list(bad_edges_ind[:, 1]) \n",
    "    ys = list(bad_edges_ind[:, 1]) + list(bad_edges_ind[:, 0])\n",
    "    vs = [1]*bad_edges_ind.shape[0]*2\n",
    "    bad_inds = scipy.sparse.coo_matrix((vs, (xs, ys)), shape=(mesh_obj.vertices.shape[0], mesh_obj.vertices.shape[0]))\n",
    "    # Make it symmetrical and add identity so each integrates from itself too, then subtract singleton edges\n",
    "    # I noticed that the number of asymmetrical edges vs the number of single edges I find from group rows\n",
    "    # Are close but different. Haven't looked into that yet. Also removing edges 1 hop away from single edges to remove bias towards\n",
    "    # Holes in the mesh that are caused by mesh construction errors as opposed to segmentation errors\n",
    "    sparse_edges = mesh_obj.edges_sparse + mesh_obj.edges_sparse.T + identity(mesh_obj.edges_sparse.shape[0]) - sparse_edges.multiply(bad_inds) - bad_inds\n",
    "    degs = mesh_obj.vertex_degree + 1\n",
    "\n",
    "    # N_iter is a smoothing parameter here. The loop below smooths the vertex error about the mesh to get more consistent connected regions\n",
    "    n_iter = 2\n",
    "    angle_sum = np.array(abs(mesh_obj.face_angles_sparse).sum(axis=1)).flatten()\n",
    "    defs = (2 * np.pi) - angle_sum\n",
    "\n",
    "    abs_defs = np.abs(defs)\n",
    "    abs_defs_i = abs_defs.copy()\n",
    "    for i in range(n_iter):\n",
    "        abs_defs_i = sparse_edges.dot(abs_defs_i) / degs\n",
    "    \n",
    "    verts_select = np.argwhere((abs_defs_i > a))# & (abs_defs < 2.5))\n",
    "\n",
    "    edges_mask = np.isin(mesh_obj.edges, verts_select)\n",
    "    edges_mask[bad_edges] = False\n",
    "    edges_select = edges_mask[:, 0] * edges_mask[:, 1]\n",
    "    edges_select = mesh_obj.edges[edges_select]\n",
    "\n",
    "    G = nx.from_edgelist(edges_select)#f_edge_sub)\n",
    "\n",
    "    ccs = nx.connected_components(G)\n",
    "    subgraphs = [G.subgraph(cc).copy() for cc in ccs]\n",
    "\n",
    "    lens = []\n",
    "    lengths = []\n",
    "    for i in tqdm(range(len(subgraphs))):\n",
    "        ns = np.array(list(subgraphs[i].nodes()))\n",
    "    #     ns = ns[abs_defs[ns ]]\n",
    "        l = len(ns)\n",
    "        if l > 20 and l < 5000:\n",
    "            lens.append(ns)\n",
    "            lengths.append(l)\n",
    "    all_nodes = set()\n",
    "    for l in lens:\n",
    "        all_nodes.update(l)\n",
    "    all_nodes = np.array(list(all_nodes))\n",
    "    # sharp_pts = mesh_obj.vertices[all_nodes]\n",
    "    centers = np.array([np.mean(mesh_obj.vertices[list(ppts)],axis=0) for ppts in lens])\n",
    "\n",
    "    return centers, lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_endpoints(mesh_obj, skel_mp):\n",
    "    # Process the skeleton to get the endpoints\n",
    "    interior_cc_mask = set()\n",
    "    el = nx.from_edgelist(skel_mp.edges)\n",
    "    comps = list(nx.connected_components(el))\n",
    "    for c in comps:\n",
    "        if len(c) < 10000:\n",
    "            n_con = mesh_obj.contains(skel_mp.vertices[list(c)])\n",
    "            if np.sum(n_con) / n_con.shape[0] > .05:\n",
    "                interior_cc_mask.update(list(c))\n",
    "    # Process the skeleton to get the endpoints\n",
    "    edges = skel_mp.edges.copy()\n",
    "\n",
    "    edge_mask = ~np.isin(edges, interior_cc_mask)\n",
    "    edge_mask = edge_mask[:, 0] + edge_mask[:, 1]\n",
    "    edges = edges[edge_mask]\n",
    "    edges_flat  = edges.flatten()\n",
    "    edge_bins = np.bincount(edges_flat) \n",
    "\n",
    "    eps = np.squeeze(np.argwhere(edge_bins==1))\n",
    "    eps_nm = skel_mp.vertices[eps]\n",
    "\n",
    "    eps_comp = distance_matrix(eps_nm, eps_nm)\n",
    "    eps_comp[eps_comp == 0] = np.inf\n",
    "    eps_thresh = np.argwhere(~(np.min(eps_comp, axis=0) < 3000))\n",
    "\n",
    "    eps = np.squeeze(eps[eps_thresh])\n",
    "    eps_nm = np.squeeze(eps_nm[eps_thresh])\n",
    "    return eps, eps_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mesh_errors(mesh_obj, centers, eps, eps_nm, lens, skel_mp):\n",
    "    print(\"Processing mesh errors\")\n",
    "    path_to_root_dict = {}\n",
    "    for ep in eps:\n",
    "        path_to_root_dict[ep] = skel_mp.path_to_root(ep)\n",
    "        \n",
    "    dists_defects = np.zeros(centers.shape[0])\n",
    "    sizes = np.zeros(centers.shape[0])\n",
    "    mesh_map = skel_mp.mesh_to_skel_map\n",
    "    closest_skel_pts = mesh_map[[l[0] for l in lens]]\n",
    "\n",
    "    # print(centers, eps_nm)\n",
    "\n",
    "    dist_matrix = distance_matrix(centers, eps_nm)\n",
    "    ct = 0\n",
    "\n",
    "    closest_tip = np.zeros((centers.shape[0]))\n",
    "\n",
    "    for center in tqdm(centers):\n",
    "    #     skel_pts_dists = np.linalg.norm(skel_mp.vertices - center, axis=1)\n",
    "    #     ep_pts_dists = np.linalg.norm(eps_nm - center, axis=1)\n",
    "        \n",
    "        closest_skel_pt = closest_skel_pts[ct]\n",
    "        min_ep = np.inf\n",
    "        eps_hit = []\n",
    "        for j, ep in enumerate(eps):\n",
    "            if closest_skel_pt in path_to_root_dict[ep]:\n",
    "                eps_hit.append(j)\n",
    "        if len(eps_hit) == 0:\n",
    "            dists_defects[ct] = np.inf\n",
    "            sizes[ct] = np.inf\n",
    "            ct+=1\n",
    "            continue\n",
    "        \n",
    "        dists = dist_matrix[ct, eps_hit]\n",
    "    #     print(dists, eps_hit, center / [4,4,40])\n",
    "        \n",
    "        amin = np.argmin(dists)\n",
    "        tip_hit = eps_hit[amin]\n",
    "        min_dist = dists[amin]\n",
    "        \n",
    "        closest_tip[ct] = tip_hit\n",
    "    #     print(np.argmin(ep_pts_dists), ep_found, eps_nm[np.argmin(ep_pts_dists)]/[4,4,40], eps_nm[j]/[4,4,40], center/[4,4,40])\n",
    "        dists_defects[ct] = min_dist\n",
    "        sizes[ct] = len(lens[ct])\n",
    "        ct+=1\n",
    "    dists_defects_sub = dists_defects[dists_defects < np.inf]\n",
    "    sizes_sub = sizes[dists_defects < np.inf]\n",
    "    centers_sub = centers[dists_defects < np.inf]\n",
    "    tips_hit_sub = closest_tip[dists_defects < np.inf]\n",
    "    closest_skel_pts_sub = closest_skel_pts[dists_defects < np.inf]\n",
    "    inds_sub = np.arange(centers.shape[0])[dists_defects < np.inf]\n",
    "\n",
    "\n",
    "    # Also ranking each component based on its PCA- if the first component is big enough, the points are mostly linear\n",
    "    # These point sets seem to be less likely to be true errors\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca_vec = np.zeros(inds_sub.shape[0])\n",
    "    for i in range(inds_sub.shape[0]):\n",
    "        pca = PCA()#n_components=2)\n",
    "        pca.fit(mesh_obj.vertices[lens[inds_sub[i]]])\n",
    "\n",
    "        pca_vec[i] = pca.explained_variance_ratio_[0]\n",
    "\n",
    "    dists_defects_sub[dists_defects_sub < 4000] = 100\n",
    "    dists_defects_norm = dists_defects_sub #/ np.max(dists_defects_sub)\n",
    "    ranks_ep = sizes_sub / dists_defects_norm * (1-pca_vec)\n",
    "    ranks = sizes_sub**2 * (1-pca_vec)\n",
    "\n",
    "    #ranks_ep_errors_filt = ranks_ep[ranks_ep > .1]\n",
    "    centers_ep_send_errors = centers_sub[np.argsort(ranks_ep)][::-1][:20]\n",
    "    final_mask_eps = np.full(centers_ep_send_errors.shape[0], True)\n",
    "    tips_hit_send_ep = tips_hit_sub[np.argsort(ranks_ep)][::-1][:20]\n",
    "    uns, nums = np.unique(tips_hit_send_ep, return_counts=True)\n",
    "\n",
    "    for un, num in zip(uns, nums):\n",
    "        if num > 1:\n",
    "            final_mask_eps[np.argwhere(tips_hit_send_ep == un)[1:]] = False\n",
    "    centers_errors_ep = centers_ep_send_errors[final_mask_eps]\n",
    "    centers_errors = centers_sub[np.argsort(ranks)[::-1]][:20]\n",
    "    return centers_errors, centers_errors_ep, ranks, ranks_ep, path_to_root_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mesh_facets(mesh_obj, skel_mp, eps, path_to_root_dict, eps_nm):\n",
    "    print(\"Processing facets\")\n",
    "    locs = np.argwhere(mesh_obj.facets_area > 50000)\n",
    "\n",
    "    mesh_map = skel_mp.mesh_to_skel_map\n",
    "    mesh_coords = mesh_obj.vertices[mesh_obj.faces]\n",
    "    mean_locs = []\n",
    "    mesh_ind = []\n",
    "    fs = []\n",
    "    for l in tqdm(locs):\n",
    "        fs.append(np.sum(mesh_obj.facets_area[l]))\n",
    "        fc = mesh_obj.facets[l[0]]\n",
    "        vert_locs = mesh_coords[fc]\n",
    "        mean_locs.append(np.mean(vert_locs[:, 0], axis=0))\n",
    "        mesh_ind.append(fc[0])\n",
    "    mesh_ind = mesh_obj.faces[mesh_ind][:, 0]\n",
    "    mean_locs = np.array(mean_locs)\n",
    "    dists_defects_facets = np.zeros(mean_locs.shape[0])\n",
    "    mesh_map_facets = skel_mp.mesh_to_skel_map\n",
    "    closest_skel_pts_facets = mesh_map[[m for m in mesh_ind]]\n",
    "    dist_matrix_facets = distance_matrix(mean_locs, eps_nm)\n",
    "    ct = 0\n",
    "\n",
    "    closest_tip_facets = np.zeros((mean_locs.shape[0]))\n",
    "\n",
    "    for center in tqdm(mean_locs):\n",
    "\n",
    "        closest_skel_pt = closest_skel_pts_facets[ct]\n",
    "        eps_hit = []\n",
    "        for j, ep in enumerate(eps):\n",
    "            if closest_skel_pt in path_to_root_dict[ep]:\n",
    "                eps_hit.append(j)\n",
    "        if len(eps_hit) == 0:\n",
    "            dists_defects_facets[ct] = np.inf\n",
    "            ct+=1\n",
    "            continue\n",
    "        \n",
    "        dists = dist_matrix_facets[ct, eps_hit]\n",
    "        \n",
    "        amin = np.argmin(dists)\n",
    "        tip_hit = eps_hit[amin]\n",
    "        min_dist = dists[amin]\n",
    "        \n",
    "        closest_tip_facets[ct] = tip_hit\n",
    "        dists_defects_facets[ct] = min_dist\n",
    "        ct+=1\n",
    "    dists_defects_sub_facets = dists_defects_facets[dists_defects_facets < np.inf]\n",
    "    sizes_sub_facets = np.array(fs)[dists_defects_facets < np.inf]\n",
    "    mean_locs_facets = mean_locs[dists_defects_facets < np.inf]\n",
    "    tips_hit_sub_facets = closest_tip_facets[dists_defects_facets < np.inf]\n",
    "    closest_skel_pts_sub_facets = closest_skel_pts_facets[dists_defects_facets < np.inf]\n",
    "    inds_sub_facets = np.arange(mean_locs.shape[0])[dists_defects_facets < np.inf]\n",
    "    ranks_ep_facets = sizes_sub_facets**2 / dists_defects_sub_facets\n",
    "    #ranks_ep_facets_filt = ranks_ep_facets[ranks_ep_facets > 2e7]\n",
    "    mean_locs_send_facets = mean_locs_facets[np.argsort(ranks_ep_facets)][::-1][:20]\n",
    "    final_mask_facets = np.full(mean_locs_send_facets.shape[0], True)\n",
    "    tips_hit_send_facets = tips_hit_sub_facets[np.argsort(ranks_ep_facets)][::-1][:20]\n",
    "    uns, nums = np.unique(tips_hit_send_facets, return_counts=True)\n",
    "\n",
    "    for un, num in zip(uns, nums):\n",
    "        if num > 1:\n",
    "            final_mask_facets[np.argwhere(tips_hit_send_facets == un)[1:]] = False\n",
    "    facets_send_final = mean_locs_send_facets[final_mask_facets] / [4,4,40]\n",
    "    return facets_send_final, ranks_ep_facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIP FINDING FUNCTION\n",
    "def error_locs_defects(root_id, soma_id = None, soma_table=None, center_collapse=True):\n",
    "    #print(\"START\", root_id)\n",
    "\n",
    "    mesh_obj = get_and_process_mesh(root_id)\n",
    "    if mesh_obj is None:\n",
    "        return None\n",
    "    # SKELETONIZE - if we are just looking for general errors, not errors at endpoints, this can be skipped\n",
    "    try:\n",
    "        if soma_table==None:\n",
    "            soma_table = get_soma(str(soma_id))\n",
    "        if soma_table[soma_table.id == soma_id].shape[0] > 0:\n",
    "            center = np.array(soma_table[soma_table.id == soma_id].pt_position)[0] * [4,4,40]\n",
    "        else:\n",
    "            center=None\n",
    "    except:\n",
    "        center = None\n",
    "    print(\"Subselecting largest connected component of mesh\")\n",
    "    mesh_obj, encapsulated_ids, max_verts = process_mesh_ccs(mesh_obj)\n",
    "\n",
    "    skel_mp = skeletonize.skeletonize_mesh(trimesh_io.Mesh(mesh_obj.vertices, \n",
    "                                            mesh_obj.faces),\n",
    "                                            invalidation_d=15000,\n",
    "                                            shape_function='cone',\n",
    "                                            collapse_function='branch',\n",
    "#                                             soma_radius = soma_radius,\n",
    "                                            soma_pt=center,\n",
    "                                            smooth_neighborhood=5,\n",
    "                                            cc_vertex_thresh=max_verts - 10\n",
    "#                                                     collapse_params = {'dynamic_threshold':True}\n",
    "                                            )\n",
    "    print(\"Skel done\")\n",
    "\n",
    "    # find edges that only occur once..  might be faster to find these in the sparse matrix..\n",
    "    centers, lens = process_defects(mesh_obj)\n",
    "    eps, eps_nm = process_endpoints(mesh_obj, skel_mp)\n",
    "\n",
    "    if len(centers) !=0:\n",
    "        centers_errors, centers_errors_ep, ranks, ranks_ep, path_to_root_dict = process_mesh_errors(mesh_obj, centers, eps, eps_nm, lens, skel_mp)\n",
    "        ranks_return = np.squeeze(ranks[np.argsort(ranks)[::-1]][:20])\n",
    "        ranks_ep_return = np.squeeze(ranks_ep[np.argsort(ranks_ep)][::-1][:20])\n",
    "    else:\n",
    "        # Assign placeholder values for each of the variables above.\n",
    "        centers_errors = np.zeros ((1,3))\n",
    "        centers_errors_ep = np.zeros ((1,3))\n",
    "        ranks = np.zeros ((1))\n",
    "        ranks_ep = np.zeros((1, 3))\n",
    "        path_to_root_dict = {}\n",
    "        for ep in eps:\n",
    "            path_to_root_dict[ep] = skel_mp.path_to_root(ep)\n",
    "\n",
    "        ranks_return = 0\n",
    "        ranks_ep_return = 0\n",
    "\n",
    "\n",
    "    #if len(centers_errors.shape) > 1 and centers_errors.shape[0] > 0 and len(centers_errors_ep.shape) > 1 and len(centers_errors_ep.shape[0] > 0):\n",
    "    #    centers_errors = centers_errors[np.min(distance_matrix(centers_errors, centers_errors_ep), axis=1)>1000]\n",
    "    facets_send_final, ranks_ep_facets = process_mesh_facets(mesh_obj, skel_mp, eps, path_to_root_dict, eps_nm)\n",
    "\n",
    "    errors_send = centers_errors / [4,4,40]\n",
    "    errors_tips_send = centers_errors_ep / [4,4,40]\n",
    "    encapsulated_centers = [e[0] for e in encapsulated_ids]\n",
    "    encapsulated_lens = [e[1] for e in encapsulated_ids]\n",
    "    sorted_encapsulated_send = np.array(encapsulated_centers)[np.argsort(encapsulated_lens)][::-1]\n",
    "\n",
    "\n",
    "\n",
    "    return sorted_encapsulated_send, facets_send_final, errors_send, errors_tips_send, np.squeeze(ranks_ep_facets[[np.argsort(ranks_ep_facets)][::-1][:20]]), ranks_return, ranks_ep_return\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSUMING output from error_locs IS: \n",
    "facets_find_final: [[x,y,z], [x2,y2,z2], etc]\n",
    "errors_tips_send: [[x,y,z], [x2,y2,z2], etc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "points = [[1,2,3], [4,5,6]]\n",
    "for x in points:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "points.append([7,8,9])\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0], [3, 4, 5]]\n"
     ]
    }
   ],
   "source": [
    "array = [[0,0,0]]\n",
    "arr2 = [3,4,5]\n",
    "array.append(arr2)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "0     1     3\n",
      "1     2     4\n",
      "   col1  col2        empty\n",
      "0     1     3  [[0, 0, 0]]\n",
      "1     2     4  [[0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df)\n",
    "df[\"empty\"] = df[\"col1\"].map(lambda x: [[0,0,0]])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_endpoints(dataframe) :\n",
    "    #assume I get in a dataframe with orphan(seg_ID), num endpoints, labelled endpoints\n",
    "    \n",
    "    #add collumn to df for predicted endpoints, add an empty array here\n",
    "    #dataframe[\"endpoints_generated\"] = [[0,0,0]]\n",
    "    dataframe[\"endpoints_generated\"] = dataframe[\"seg_id\"].map(lambda x: [()])\n",
    "    #first we need to iterate through the given dataframe row by row\n",
    "    count = 0\n",
    "    for index, row in dataframe.iterrows(): \n",
    "        #get the neuron/orphan seg_ID\n",
    "        if count == 3:\n",
    "            break\n",
    "        count = count + 1\n",
    "        seg_id = row[\"seg_id\"]\n",
    "        #pass the seg_id into the generating function\n",
    "        sorted_encapsulated_send, facets_send_final, errors_send, errors_tips_send, dummy, dummy2, dummy3 = error_locs_defects(seg_id)\n",
    "        #add the predicted endpoints into the dataframe row\n",
    "        for endpoint in facets_send_final:\n",
    "            #if the endpoint is 0,0,0 then we skip \n",
    "            if(np.all(0)):\n",
    "                break\n",
    "            row[\"endpoints_generated\"].append(endpoint)\n",
    "        for endpoints in errors_tips_send:\n",
    "            if(np.all(0)):\n",
    "                break\n",
    "            row[\"endpoints_generated\"].append(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Mesh\n",
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n",
      "Vertices:  7993\n",
      "Subselecting largest connected component of mesh\n",
      "Processing CC's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7992/7992 [00:00<00:00, 1281771.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skel done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 26/26 [00:00<00:00, 172277.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing facets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6/6 [00:00<00:00, 8012.04it/s]\n",
      "100%|| 6/6 [00:00<00:00, 35746.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Mesh\n",
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n",
      "Vertices:  21335\n",
      "Subselecting largest connected component of mesh\n",
      "Processing CC's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21334/21334 [00:00<00:00, 1435098.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skel done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 87/87 [00:00<00:00, 47831.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mesh errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<00:00, 18355.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing facets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 37/37 [00:00<00:00, 16757.29it/s]\n",
      "100%|| 37/37 [00:00<00:00, 47084.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Mesh\n",
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n",
      "Vertices:  2282\n",
      "Subselecting largest connected component of mesh\n",
      "Processing CC's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2281/2281 [00:00<00:00, 529335.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skel done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:00<00:00, 113359.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mesh errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 25575.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing facets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8/8 [00:00<00:00, 17058.68it/s]\n",
      "100%|| 8/8 [00:00<00:00, 96420.78it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_endpoints(orphans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [(), [402970.1091549296, 229214.63028169013, 2...\n",
      "1      [(), [409125.1111111111, 219484.22222222222, 2...\n",
      "2                                                   [()]\n",
      "3                                                   [()]\n",
      "4                                                   [()]\n",
      "                             ...                        \n",
      "127                                                 [()]\n",
      "128                                                 [()]\n",
      "129                                                 [()]\n",
      "130                                                 [()]\n",
      "131                                                 [()]\n",
      "Name: endpoints_generated, Length: 132, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(orphans[\"endpoints_generated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402584, 228856, 23991)\n",
      "(402985, 229235, 23554)\n"
     ]
    }
   ],
   "source": [
    "for orphan in orphans[\"endpoints\"][0]:\n",
    "    print(orphan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Mesh\n",
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n",
      "Vertices:  7993\n",
      "Subselecting largest connected component of mesh\n",
      "Processing CC's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7992/7992 [00:00<00:00, 1294442.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skel done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 26/26 [00:00<00:00, 165732.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing facets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6/6 [00:00<00:00, 6501.12it/s]\n",
      "100%|| 6/6 [00:00<00:00, 32640.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[402970.10915493 229214.63028169  23552.55      ]\n",
      " [402527.5625     228866.3125      23991.45      ]]\n",
      "[[0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#example to see outputs\n",
    "sorted_encapsulated_send, facets_send_final, errors_send, errors_tips_send, dummy, dummy2, dummy3 = error_locs_defects(864691135909994000)\n",
    "print(facets_send_final)\n",
    "print(errors_tips_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging\n",
    "\n",
    "x = np.zeros((10,3))\n",
    "y = np.ones((10,3))\n",
    "dist_matrix = distance_matrix(x,y)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_eps_acc(gt_endpoints, pred_endpoints, threshold):\n",
    "    # Calculate distances\n",
    "    dist_matrix = np.array(spatial.distance.cdist(gt_endpoints, pred_endpoints, metric = 'euclidean'))\n",
    "\n",
    "    # Apply threshold\n",
    "    dist_matrix[dist_matrix > threshold] = 0\n",
    "\n",
    "    # Calculating accuracy\n",
    "    valid_eps = np.count_nonzero(dist_matrix, axis = 1)\n",
    "    accuracy = np.count_nonzero(valid_eps) / len(gt_endpoints)\n",
    "\n",
    "    # If more than one valid endpoint found for a single ground truth endpoint, add the other valid endpoints to extra_valid_pairs\n",
    "    extra_valid_pairs = []\n",
    "    [[extra_valid_pairs.append([gt_endpoints[i], pred_endpoints[index]]) \\\n",
    "        for index, j in enumerate(dist_matrix[i]) if j != np.min(dist_matrix[i][dist_matrix[i] != 0]) if j != 0] \\\n",
    "            for i in valid_eps if i > 1]\n",
    "\n",
    "    return accuracy, extra_valid_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=[\"seg_id\", \"num_gt_eps\", \"gt_eps\", \"num_pred_eps\", \"pred_eps\"])\n",
    "data.loc[len(data.index)] = [864691136577830164, 6, [\n",
    "    [402188, 228684, 24029], [401258, 224832, 24029], [401314, 228366, 24424], \\\n",
    "    [400199, 220721, 24029], [397870, 232292, 24004], [403272, 227529, 24394]], 6, \\\n",
    "    [[400292, 220879, 24027], [401253, 228342, 24408], [401253, 228342, 24409],\n",
    "        [402923, 227458, 24372], [402099, 228716, 24037], [402627, 231471, 24026]]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, extra_valid_pairs = pred_eps_acc(\n",
    "    data.loc[0, \"gt_eps\"], data.loc[0, \"pred_eps\"], 100)\n",
    "print(acc)\n",
    "print(extra_valid_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
