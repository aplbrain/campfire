{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections.abc import Iterable\n",
    "from agents import data_loader\n",
    "from caveclient import CAVEclient\n",
    "from cloudvolume import CloudVolume, VolumeCutout\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from orphan_extension.utils.cast_to_bounds import cast_points_within_bounds\n",
    "from tip_finding import tip_finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OrphanError(Exception):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Orphans:\n",
    "    def __init__(self, x_min, x_max, y_min, y_max, z_min, z_max):\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.y_min = y_min\n",
    "        self.y_max = y_max\n",
    "        self.z_min = z_min\n",
    "        self.z_max = z_max\n",
    "\n",
    "    # Gets all the seg ids within a given subvolume and organizes by size of process. Returns list of tuples: (seg_id, size)\n",
    "    def get_unique_seg_ids_em(self, coords=None) -> list:\n",
    "        if (coords != None and len(coords) != 6):  # CHANGE THE ERROR THROWN!\n",
    "            raise OrphanError(\"get_unqiue_seg_ids_em need 6 coordinates!!\")\n",
    "        if (coords != None):\n",
    "            x_min = coords[0]\n",
    "            x_max = coords[1]\n",
    "            y_min = coords[2]\n",
    "            y_max = coords[3]\n",
    "            z_min = coords[4]\n",
    "            z_max = coords[5]\n",
    "        else:\n",
    "            x_min = self.x_min\n",
    "            x_max = self.x_max\n",
    "            y_min = self.y_min\n",
    "            y_max = self.y_max\n",
    "            z_min = self.z_min\n",
    "            z_max = self.z_max\n",
    "        # Get entire EM data - uncomment after testing\n",
    "        # em = CloudVolume('s3://bossdb-open-data/iarpa_microns/minnie/minnie65/seg', use_https=True, mip=0, parallel=True, fill_missing=True, progress=True)\n",
    "\n",
    "        # Get seg ids in the specified subvolume\n",
    "        seg_ids_sv = data_loader.get_seg(x_min, x_max, y_min,\n",
    "                                         y_max, z_min, z_max)\n",
    "\n",
    "        # Get rid of the 4th dimension since its magnitude is 1\n",
    "        seg_ids_sv = np.squeeze(seg_ids_sv)\n",
    "\n",
    "        # List of all unique seg ids in the 3d subvolume\n",
    "        unique_seg_ids_sv = np.unique(seg_ids_sv)\n",
    "\n",
    "        # Removing the first element (artifacts) of unique_seg_ids_sv\n",
    "        \"\"\"\n",
    "        Drop all zeros in array instead of only first, handles edge cases\n",
    "        unique_seg_ids_sv = np.delete(unique_seg_ids_sv, 0)\n",
    "        \"\"\"\n",
    "\n",
    "        unique_seg_ids_sv = unique_seg_ids_sv[unique_seg_ids_sv != 0]\n",
    "        unique_seg_ids_sv = unique_seg_ids_sv[unique_seg_ids_sv != None]\n",
    "\n",
    "        # Organizing seg ids in subvolume by size\n",
    "        seg_ids_by_size = {}\n",
    "        for seg_id in (pbar := tqdm(unique_seg_ids_sv)):\n",
    "            pbar.set_description('Organizing seg_ids by size')\n",
    "            # seg_ids_by_size[seg_id] = int(em[em == seg_id].sum()) # Uncomment after testing to organize seg ids by size considering whole data\n",
    "            seg_ids_by_size[seg_id] = [int(\n",
    "                np.sum(seg_ids_sv == seg_id))]\n",
    "\n",
    "        seg_ids_by_size = sorted(seg_ids_by_size.items(),\n",
    "                                 key=lambda x: x[1], reverse=True)\n",
    "        # Returns a list of tuples with first element as seg id, second elmenet of tuple is a list containing size\n",
    "        return seg_ids_by_size  # Sorted in descending order\n",
    "\n",
    "    # Get the list of orphans within a given subvolume organized by largest orphan in subvolume first\n",
    "    def get_orphans(self, coords=None) -> dict:\n",
    "\n",
    "        unique_seg_ids = self.get_unique_seg_ids_em(coords)\n",
    "\n",
    "        # Getting all the orphans\n",
    "        orphans = {}\n",
    "\n",
    "        for seg_id_and_size in (pbar := tqdm(unique_seg_ids)):\n",
    "            pbar.set_description('Finding orphans')\n",
    "            seg_id = seg_id_and_size[0]\n",
    "            if (data_loader.get_num_soma(str(seg_id)) == 0):\n",
    "                orphans[seg_id] = [seg_id_and_size[1][0]]\n",
    "\n",
    "        return orphans  # dict of seg_ids that are orphans in given subvolume\n",
    "\n",
    "    # Input: processes is a dictionary with key = seg_id, value = list of attributes\n",
    "    # Returns: updated processes so that value also includes the type of the process\n",
    "    def get_process_type(self, processes: dict) -> dict:\n",
    "        for seg_id, attributes in (pbar := tqdm(processes.items())):\n",
    "            pbar.set_description('Finding process type')\n",
    "            num_pre_synapses, num_post_synapses = data_loader.get_syn_counts(\n",
    "                str(seg_id))\n",
    "            if (num_pre_synapses > num_post_synapses):\n",
    "                attributes.append('axon')\n",
    "            elif (num_post_synapses > num_pre_synapses):\n",
    "                attributes.append('dendrite')\n",
    "            else:\n",
    "                attributes.append('unconfirmed')\n",
    "\n",
    "        return processes\n",
    "\n",
    "    def get_pot_extensions(self, endpoint_coords):\n",
    "\n",
    "        if (len(endpoint_coords) != 3):\n",
    "            # FIX THIS - SHOULD BE DIFF TYPE OF ERROR\n",
    "            raise OrphanError(\n",
    "                \"get_pot_extension needs all 3 coordinates of endpoint to extend!\")\n",
    "\n",
    "        # Get the coordinates of the bounding box around the endpoint\n",
    "        endpoint_bounding_box_coords = bounding_box_coords(endpoint_coords)\n",
    "\n",
    "        # Get a preliminary list of all seg ids within bounding box\n",
    "        # pot_ex = self.get_unique_seg_ids_em(*endpoint_bounding_box_coords)\n",
    "        pot_ex = self.get_unique_seg_ids_em(endpoint_bounding_box_coords)\n",
    "\n",
    "        # Get seg id of current fragment\n",
    "        curr_process_seg_id = data_loader.get_seg(\n",
    "            endpoint_coords[0], endpoint_coords[0], endpoint_coords[1], endpoint_coords[1], endpoint_coords[2], endpoint_coords[2])\n",
    "\n",
    "        # Get type of all processes\n",
    "        pot_ex = dict(pot_ex)\n",
    "        pot_ex = self.get_process_type(pot_ex)\n",
    "\n",
    "        # Get type of current process\n",
    "        curr_process_type = pot_ex[curr_process_seg_id][1]\n",
    "\n",
    "        # Remove current seg id from the list of potential extensions - REWORK TO USE DELETE\n",
    "        # pot_ex = pot_ex[str(pot_ex) != str(curr_process_seg_id)]\n",
    "        del pot_ex[curr_process_seg_id]\n",
    "\n",
    "        # Filter out all other processes whose type!= current process type\n",
    "        pot_ex = remove_diff_types(curr_process_type, pot_ex)\n",
    "\n",
    "        return pot_ex  # Return all potential extensions after removing confirmed other types\n",
    "\n",
    "\n",
    "def bounding_box_coords(point: Iterable, boxdim: Iterable = [100, 100, 100]) -> list:\n",
    "    # Data bounds not validated\n",
    "    data_bounds = [26000, 220608, 30304, 161376, 14825, 27881]\n",
    "\n",
    "    # Confirm that entry is 3dim\n",
    "    if len(point) != 3:\n",
    "        raise OrphanError(\n",
    "            \"Point passed to func bounding_box_coords() must be an iterable of length 3.\")\n",
    "    if len(boxdim) != 3:\n",
    "        raise OrphanError(\n",
    "            \"Box dimensions passed to func bounding_box_coords() must be 3 dimensional\")\n",
    "\n",
    "    # Check bound validity and cast to new bounds\n",
    "    casted_bounds = cast_points_within_bounds(point, data_bounds, boxdim)\n",
    "\n",
    "    return casted_bounds\n",
    "\n",
    "\n",
    "def remove_diff_types(process_type, pot_ex):\n",
    "    for seg_id, attributes in pot_ex.items():\n",
    "        if (process_type not in attributes or \"unconfirmed\" not in attributes):\n",
    "            del pot_ex[seg_id]\n",
    "\n",
    "    return pot_ex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cast_points_within_bounds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bounds \u001b[39m=\u001b[39m bounding_box_coords([\u001b[39m115267\u001b[39;49m, \u001b[39m91839\u001b[39;49m, \u001b[39m21305\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(bounds)\n\u001b[1;32m      3\u001b[0m orphanclass \u001b[39m=\u001b[39m Orphans(bounds[\u001b[39m0\u001b[39m], bounds[\u001b[39m1\u001b[39m],\n\u001b[1;32m      4\u001b[0m                       bounds[\u001b[39m2\u001b[39m], bounds[\u001b[39m3\u001b[39m], bounds[\u001b[39m4\u001b[39m], bounds[\u001b[39m5\u001b[39m])\n",
      "Cell \u001b[0;32mIn [5], line 143\u001b[0m, in \u001b[0;36mbounding_box_coords\u001b[0;34m(point, boxdim)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[39mraise\u001b[39;00m OrphanError(\n\u001b[1;32m    140\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBox dimensions passed to func bounding_box_coords() must be 3 dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[39m# Check bound validity and cast to new bounds\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m casted_bounds \u001b[39m=\u001b[39m cast_points_within_bounds(point, data_bounds, boxdim)\n\u001b[1;32m    145\u001b[0m \u001b[39mreturn\u001b[39;00m casted_bounds\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cast_points_within_bounds' is not defined"
     ]
    }
   ],
   "source": [
    "bounds = bounding_box_coords([115267, 91839, 21305])\n",
    "print(bounds)\n",
    "orphanclass = Orphans(bounds[0], bounds[1],\n",
    "                      bounds[2], bounds[3], bounds[4], bounds[5])\n",
    "orphans = orphanclass.get_orphans()\n",
    "print(\"Number of orphans:\", len(orphans))\n",
    "orphanclass.get_process_type(orphans)\n",
    "print(\"Orphans\", orphans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orphans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m total_size \u001b[39m=\u001b[39m orphans\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m      2\u001b[0m total_size \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(total_size)\n\u001b[1;32m      3\u001b[0m total_size \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(total_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'orphans' is not defined"
     ]
    }
   ],
   "source": [
    "total_size = orphans.values()\n",
    "total_size = list(total_size)\n",
    "total_size = np.array(total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_array = total_size[:,0].astype(int)\n",
    "\n",
    "np.sum(int_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_seg_ids_subvolume = orphanclass.get_unique_seg_ids_em(bounds)\n",
    "unique_seg_ids_subvolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_seg_ids_size = np.array(unique_seg_ids_subvolume)\n",
    "total_seg_ids_size = total_seg_ids_size[:,1]\n",
    "sum = 0\n",
    "for i in total_seg_ids_size:\n",
    "    # print(i)\n",
    "    sum+=i[0]\n",
    "\n",
    "print()\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_ids = [864691136909215598, 864691135521264882, 864691135368930546, 864691135918483376, 864691135804594461, 864691136914365806, 864691135395943378, 864691135478343235, 864691135648168388, 864691136000419720, 864691135449037042, 864691136181973462, 864691135582201586, 864691133035107425, 864691136913731182, 864691135407650258, 864691135968211902, 864691132647778343,\n",
    "           864691135401901778, 864691135104027483, 864691133716301031, 864691132647775271, 864691132647776807, 864691135648134852, 864691135407637970, 864691133035106657, 864691135648947396, 864691133456842377, 864691132647776295, 864691133716301287, 864691133035107169, 864691132647777575, 864691135804092189, 864691135793272349, 864691133456842633, 864691132647777063]\n",
    "\n",
    "for i in seg_ids:\n",
    "    print(data_loader.get_num_soma(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
