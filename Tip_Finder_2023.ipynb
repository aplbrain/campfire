{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "from meshparty import skeletonize, trimesh_io\n",
    "from caveclient import CAVEclient\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import datetime\n",
    "import networkx as nx\n",
    "from scipy.sparse import identity\n",
    "from scipy.spatial import distance_matrix\n",
    "import scipy \n",
    "from tqdm import tqdm\n",
    "# import aws\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pyembree\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial as spatial\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orphans = pd.read_csv(\"/Users/sheeltanna/Desktop/AGT_REPO/campfire/GT_30_Orphans_Spring_2023 - Sheet1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_array(x):\n",
    "    res = list(map(str.strip, x.split('; ')))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphans['endpoints'] = orphans['endpoints'].map(lambda x: list(map(str.strip, x.split('; '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert from string list to 2-d array\n",
    "def convert_to_array(row):\n",
    "    count = 0\n",
    "    result = []\n",
    "    for endpoint in row[\"endpoints\"]:\n",
    "        # endpoint = tuple(map(int, endpoint.split(', ')))\n",
    "        endpoint = eval(endpoint)\n",
    "        # print()\n",
    "        # print(endpoint)\n",
    "        # print(type(endpoint))\n",
    "        if(count == 0):\n",
    "            result = np.array(endpoint)\n",
    "            count = count + 1\n",
    "        else:\n",
    "            result = np.vstack((result, np.array(endpoint)))\n",
    "            count = count + 1\n",
    "            #result = np.concatenate(result, list(tuple))\n",
    "    #check if there was only 1 point, convert to 2-d array:\n",
    "    # if(type(result) == list):\n",
    "        \n",
    "    if(count == 1 and result.size != 0):\n",
    "        result = result.reshape(1,3)\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphans[\"real_endpoints\"] = orphans.apply(convert_to_array, axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIP FINDER FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_process_mesh(root_id):\n",
    "    datastack_name = \"minnie65_phase3_v1\"\n",
    "    client = CAVEclient(datastack_name)\n",
    "    vol = CloudVolume(\n",
    "        client.info.segmentation_source(),\n",
    "        use_https=True,\n",
    "        progress=False,\n",
    "        bounded=False,\n",
    "        fill_missing=True,\n",
    "        secrets={\"token\": client.auth.token}\n",
    "    )\n",
    "    print(\"Downloading Mesh\")\n",
    "    mesh = vol.mesh.get(str(root_id))[root_id]\n",
    "    mesh_obj = trimesh.Trimesh(np.divide(mesh.vertices, np.array([1,1,1])), mesh.faces)\n",
    "    print(\"Vertices: \", mesh.vertices.shape[0])\n",
    "\n",
    "    if mesh_obj.volume > 4000000000000:\n",
    "        print(\"TOO BIG, SKIPPING\")\n",
    "        #queue_url_endpoints = sqs.get_or_create_queue(\"root_ids_functional_dlqueue\")\n",
    "\n",
    "        #entries=sqs.construct_rootid_entries([root_id])\n",
    "\n",
    "        #sqs.send_batch(queue_url_endpoints, entries)\n",
    "\n",
    "        return None\n",
    "    trimesh.repair.fix_normals(mesh_obj)\n",
    "    mesh_obj.fill_holes()\n",
    "\n",
    "    return mesh_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soma(soma_id:str):\n",
    "    cave_client = CAVEclient('minnie65_phase3_v1')\n",
    "    soma = cave_client.materialize.query_table(\n",
    "        \"nucleus_neuron_svm\",\n",
    "        filter_equal_dict={'id':soma_id}\n",
    "    )\n",
    "    return soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mesh_ccs(mesh_obj):\n",
    "    print(\"Processing CC's\")\n",
    "    ccs_graph = trimesh.graph.connected_components(mesh_obj.edges)\n",
    "    ccs_len = [len(c) for c in ccs_graph]\n",
    "\n",
    "    # Subselect the parts of the mesh that are not inside one another \n",
    "    # the other components are an artifact of the soma seg and small unfilled sections\n",
    "    largest_component = ccs_graph[np.argmax(ccs_len)]\n",
    "    largest_component_remap = np.arange(ccs_graph[np.argmax(ccs_len)].shape[0])\n",
    "    face_dict = {largest_component[i]:largest_component_remap[i] for i in range(largest_component.shape[0])}\n",
    "\n",
    "    new_faces_mask = np.isin(mesh_obj.faces, list(face_dict.keys()))\n",
    "    new_faces_mask = new_faces_mask[:, 0]*new_faces_mask[:, 1]*new_faces_mask[:, 2]\n",
    "\n",
    "    new_faces = np.vectorize(face_dict.get)(mesh_obj.faces[new_faces_mask])\n",
    "    new_faces = new_faces[new_faces[:, 0] != None]\n",
    "    largest_component_mesh = trimesh.Trimesh(mesh_obj.vertices[largest_component], new_faces)\n",
    "\n",
    "    all_ids = set(largest_component)\n",
    "    encapsulated_ids = []\n",
    "\n",
    "    for i in range(1, len(ccs_graph)):\n",
    "        n_con = largest_component_mesh.contains(mesh_obj.vertices[ccs_graph[i]])\n",
    "        if np.sum(n_con) / n_con.shape[0] == 0 and n_con.shape[0] > 50:\n",
    "            all_ids.update(ccs_graph[i])\n",
    "        else:\n",
    "            if len(ccs_graph[i]) < 1000:\n",
    "                encapsulated_ids.append((np.mean(mesh_obj.vertices[ccs_graph[i]], axis=0)/[4,4,40], len(ccs_graph[i])))\n",
    "            \n",
    "    all_component = np.array(list(ccs_graph[np.argmax(ccs_len)]))\n",
    "    all_component_remap = np.arange(all_component.shape[0])\n",
    "    face_dict = {all_component[i]:all_component_remap[i] for i in range(all_component.shape[0])}\n",
    "    new_faces_mask = np.isin(mesh_obj.faces, list(face_dict.keys()))\n",
    "    new_faces_mask = new_faces_mask[:, 0]*new_faces_mask[:, 1]*new_faces_mask[:, 2]\n",
    "\n",
    "    new_faces = np.vectorize(face_dict.get)(mesh_obj.faces[new_faces_mask])\n",
    "    new_faces[new_faces[:, 0] != None]\n",
    "    \n",
    "    largest_component_mesh = trimesh.Trimesh(mesh_obj.vertices[all_component], new_faces)\n",
    "    \n",
    "    mesh_obj = largest_component_mesh\n",
    "    return mesh_obj, encapsulated_ids, np.max(ccs_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_defects(mesh_obj, a=.75):\n",
    "    bad_edges = trimesh.grouping.group_rows(\n",
    "        mesh_obj.edges_sorted, require_count=1)\n",
    "    bad_edges_ind = mesh_obj.edges[bad_edges]\n",
    "    sparse_edges = mesh_obj.edges_sparse\n",
    "    xs = list(bad_edges_ind[:, 0]) + list(bad_edges_ind[:, 1]) \n",
    "    ys = list(bad_edges_ind[:, 1]) + list(bad_edges_ind[:, 0])\n",
    "    vs = [1]*bad_edges_ind.shape[0]*2\n",
    "    bad_inds = scipy.sparse.coo_matrix((vs, (xs, ys)), shape=(mesh_obj.vertices.shape[0], mesh_obj.vertices.shape[0]))\n",
    "    # Make it symmetrical and add identity so each integrates from itself too, then subtract singleton edges\n",
    "    # I noticed that the number of asymmetrical edges vs the number of single edges I find from group rows\n",
    "    # Are close but different. Haven't looked into that yet. Also removing edges 1 hop away from single edges to remove bias towards\n",
    "    # Holes in the mesh that are caused by mesh construction errors as opposed to segmentation errors\n",
    "    sparse_edges = mesh_obj.edges_sparse + mesh_obj.edges_sparse.T + identity(mesh_obj.edges_sparse.shape[0]) - sparse_edges.multiply(bad_inds) - bad_inds\n",
    "    degs = mesh_obj.vertex_degree + 1\n",
    "\n",
    "    # N_iter is a smoothing parameter here. The loop below smooths the vertex error about the mesh to get more consistent connected regions\n",
    "    n_iter = 2\n",
    "    angle_sum = np.array(abs(mesh_obj.face_angles_sparse).sum(axis=1)).flatten()\n",
    "    defs = (2 * np.pi) - angle_sum\n",
    "\n",
    "    abs_defs = np.abs(defs)\n",
    "    abs_defs_i = abs_defs.copy()\n",
    "    for i in range(n_iter):\n",
    "        abs_defs_i = sparse_edges.dot(abs_defs_i) / degs\n",
    "    \n",
    "    verts_select = np.argwhere((abs_defs_i > a))# & (abs_defs < 2.5))\n",
    "\n",
    "    edges_mask = np.isin(mesh_obj.edges, verts_select)\n",
    "    edges_mask[bad_edges] = False\n",
    "    edges_select = edges_mask[:, 0] * edges_mask[:, 1]\n",
    "    edges_select = mesh_obj.edges[edges_select]\n",
    "\n",
    "    G = nx.from_edgelist(edges_select)#f_edge_sub)\n",
    "\n",
    "    ccs = nx.connected_components(G)\n",
    "    subgraphs = [G.subgraph(cc).copy() for cc in ccs]\n",
    "\n",
    "    lens = []\n",
    "    lengths = []\n",
    "    for i in tqdm(range(len(subgraphs))):\n",
    "        ns = np.array(list(subgraphs[i].nodes()))\n",
    "    #     ns = ns[abs_defs[ns ]]\n",
    "        l = len(ns)\n",
    "        if l > 20 and l < 5000:\n",
    "            lens.append(ns)\n",
    "            lengths.append(l)\n",
    "    all_nodes = set()\n",
    "    for l in lens:\n",
    "        all_nodes.update(l)\n",
    "    all_nodes = np.array(list(all_nodes))\n",
    "    # sharp_pts = mesh_obj.vertices[all_nodes]\n",
    "    centers = np.array([np.mean(mesh_obj.vertices[list(ppts)],axis=0) for ppts in lens])\n",
    "\n",
    "    return centers, lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_endpoints(mesh_obj, skel_mp):\n",
    "    # Process the skeleton to get the endpoints\n",
    "    interior_cc_mask = set()\n",
    "    el = nx.from_edgelist(skel_mp.edges)\n",
    "    comps = list(nx.connected_components(el))\n",
    "    for c in comps:\n",
    "        if len(c) < 100:\n",
    "            n_con = mesh_obj.contains(skel_mp.vertices[list(c)])\n",
    "            if np.sum(n_con) / n_con.shape[0] > .10:\n",
    "                interior_cc_mask.update(list(c))\n",
    "    # Process the skeleton to get the endpoints\n",
    "    edges = skel_mp.edges.copy()\n",
    "\n",
    "    edge_mask = ~np.isin(edges, interior_cc_mask)\n",
    "    edge_mask = edge_mask[:, 0] + edge_mask[:, 1]\n",
    "    edges = edges[edge_mask]\n",
    "    edges_flat  = edges.flatten()\n",
    "    edge_bins = np.bincount(edges_flat) \n",
    "\n",
    "    eps = np.squeeze(np.argwhere(edge_bins==1))\n",
    "    eps_nm = skel_mp.vertices[eps]\n",
    "\n",
    "    eps_comp = distance_matrix(eps_nm, eps_nm)\n",
    "    eps_comp[eps_comp == 0] = np.inf\n",
    "    eps_thresh = np.argwhere(~(np.min(eps_comp, axis=0) < 3000))\n",
    "\n",
    "    eps = np.squeeze(eps[eps_thresh])\n",
    "    eps_nm = np.squeeze(eps_nm[eps_thresh])\n",
    "    return eps, eps_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mesh_errors(mesh_obj, centers, eps, eps_nm, lens, skel_mp):\n",
    "    print(\"Processing mesh errors\")\n",
    "    # path_to_root_dict = {}\n",
    "    # for ep in eps:\n",
    "    #     path_to_root_dict[ep] = skel_mp.path_to_root(ep)\n",
    "        \n",
    "    dists_defects = np.zeros(centers.shape[0])\n",
    "    sizes = np.zeros(centers.shape[0])\n",
    "    mesh_map = skel_mp.mesh_to_skel_map\n",
    "    closest_skel_pts = mesh_map[[l[0] for l in lens]]\n",
    "\n",
    "    # print(centers, eps_nm)\n",
    "\n",
    "    dist_matrix = distance_matrix(centers, eps_nm)\n",
    "    ct = 0\n",
    "\n",
    "    closest_tip = np.zeros((centers.shape[0]))\n",
    "\n",
    "    for center in tqdm(centers):\n",
    "    #     skel_pts_dists = np.linalg.norm(skel_mp.vertices - center, axis=1)\n",
    "    #     ep_pts_dists = np.linalg.norm(eps_nm - center, axis=1)\n",
    "        \n",
    "        # closest_skel_pt = closest_skel_pts[ct]\n",
    "        min_ep = np.inf\n",
    "        eps_hit = []\n",
    "        for j, ep in enumerate(eps):\n",
    "            # if closest_skel_pt in path_to_root_dict[ep]:\n",
    "            #     eps_hit.append(j)\n",
    "            eps_hit.append(j)\n",
    "\n",
    "        if len(eps_hit) == 0:\n",
    "            dists_defects[ct] = np.inf\n",
    "            sizes[ct] = np.inf\n",
    "            ct+=1\n",
    "            continue\n",
    "        \n",
    "        dists = dist_matrix[ct, eps_hit]\n",
    "    #     print(dists, eps_hit, center / [4,4,40])\n",
    "        \n",
    "        amin = np.argmin(dists)\n",
    "        tip_hit = eps_hit[amin]\n",
    "        min_dist = dists[amin]\n",
    "        \n",
    "        closest_tip[ct] = tip_hit\n",
    "    #     print(np.argmin(ep_pts_dists), ep_found, eps_nm[np.argmin(ep_pts_dists)]/[4,4,40], eps_nm[j]/[4,4,40], center/[4,4,40])\n",
    "        dists_defects[ct] = min_dist\n",
    "        sizes[ct] = len(lens[ct])\n",
    "        ct+=1\n",
    "    dists_defects_sub = dists_defects[dists_defects < 5000]\n",
    "    sizes_sub = sizes[dists_defects < 5000]\n",
    "    centers_sub = centers[dists_defects < 5000]\n",
    "    tips_hit_sub = closest_tip[dists_defects < 5000]\n",
    "    closest_skel_pts_sub = closest_skel_pts[dists_defects < 5000]\n",
    "    inds_sub = np.arange(centers.shape[0])[dists_defects < 5000]\n",
    "\n",
    "\n",
    "    # Also ranking each component based on its PCA- if the first component is big enough, the points are mostly linear\n",
    "    # These point sets seem to be less likely to be true errors\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca_vec = np.zeros(inds_sub.shape[0])\n",
    "    for i in range(inds_sub.shape[0]):\n",
    "        pca = PCA()#n_components=2)\n",
    "        pca.fit(mesh_obj.vertices[lens[inds_sub[i]]])\n",
    "\n",
    "        pca_vec[i] = pca.explained_variance_ratio_[0]\n",
    "\n",
    "    dists_defects_sub[dists_defects_sub < 4000] = 100\n",
    "    dists_defects_norm = dists_defects_sub #/ np.max(dists_defects_sub)\n",
    "    ranks_ep = sizes_sub / dists_defects_norm * (1-pca_vec)\n",
    "    ranks = sizes_sub**2 * (1-pca_vec)\n",
    "\n",
    "    #ranks_ep_errors_filt = ranks_ep[ranks_ep > .1]\n",
    "    centers_ep_send_errors = centers_sub[np.argsort(ranks_ep)][::-1][:20]\n",
    "    final_mask_eps = np.full(centers_ep_send_errors.shape[0], True)\n",
    "    tips_hit_send_ep = tips_hit_sub[np.argsort(ranks_ep)][::-1][:20]\n",
    "    uns, nums = np.unique(tips_hit_send_ep, return_counts=True)\n",
    "\n",
    "    for un, num in zip(uns, nums):\n",
    "        if num > 1:\n",
    "            final_mask_eps[np.argwhere(tips_hit_send_ep == un)[1:]] = False\n",
    "    centers_errors_ep = centers_ep_send_errors[final_mask_eps]\n",
    "    centers_errors = centers_sub[np.argsort(ranks)[::-1]][:20]\n",
    "    return centers_errors, centers_errors_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mesh_facets(mesh_obj, skel_mp, eps, eps_nm, facet_area_threshold=30000):\n",
    "    #changed threshold of facets to 3000 to match changes performed on processed in analysis CELLS\n",
    "    print(\"Processing facets\")\n",
    "    #can possibly change param here\n",
    "    #threshold on size of flat area\n",
    "    locs = np.argwhere(mesh_obj.facets_area > facet_area_threshold)\n",
    "\n",
    "    mesh_map = skel_mp.mesh_to_skel_map\n",
    "    mesh_coords = mesh_obj.vertices[mesh_obj.faces]\n",
    "    mean_locs = []\n",
    "    mesh_ind = []\n",
    "    fs = []\n",
    "    for l in tqdm(locs):\n",
    "        fs.append(np.sum(mesh_obj.facets_area[l]))\n",
    "        fc = mesh_obj.facets[l[0]]\n",
    "        vert_locs = mesh_coords[fc]\n",
    "        mean_locs.append(np.mean(vert_locs[:, 0], axis=0))\n",
    "        mesh_ind.append(fc[0])\n",
    "    mesh_ind = mesh_obj.faces[mesh_ind][:, 0]\n",
    "    mean_locs = np.array(mean_locs)\n",
    "    dists_defects_facets = np.zeros(mean_locs.shape[0])\n",
    "    mesh_map_facets = skel_mp.mesh_to_skel_map\n",
    "    closest_skel_pts_facets = mesh_map[[m for m in mesh_ind]]\n",
    "    dist_matrix_facets = distance_matrix(mean_locs, eps_nm)\n",
    "    ct = 0\n",
    "\n",
    "    closest_tip_facets = np.zeros((mean_locs.shape[0]))\n",
    "\n",
    "    for center in tqdm(mean_locs):\n",
    "\n",
    "        closest_skel_pt = closest_skel_pts_facets[ct]\n",
    "        eps_hit = []\n",
    "        for j, ep in enumerate(eps):\n",
    "            # if closest_skel_pt in path_to_root_dict[ep]:\n",
    "            #     eps_hit.append(j)\n",
    "            eps_hit.append(j)\n",
    "\n",
    "        if len(eps_hit) == 0:\n",
    "            dists_defects_facets[ct] = np.inf\n",
    "            ct+=1\n",
    "            continue\n",
    "        \n",
    "        dists = dist_matrix_facets[ct, eps_hit]\n",
    "        \n",
    "        amin = np.argmin(dists)\n",
    "        tip_hit = eps_hit[amin]\n",
    "        min_dist = dists[amin]\n",
    "        \n",
    "        closest_tip_facets[ct] = tip_hit\n",
    "        dists_defects_facets[ct] = min_dist\n",
    "        ct+=1\n",
    "    dists_defects_sub_facets = dists_defects_facets[dists_defects_facets < 2000]\n",
    "    sizes_sub_facets = np.array(fs)[dists_defects_facets < 2000]\n",
    "    mean_locs_facets = mean_locs[dists_defects_facets < 2000]\n",
    "    tips_hit_sub_facets = closest_tip_facets[dists_defects_facets < 2000]\n",
    "    closest_skel_pts_sub_facets = closest_skel_pts_facets[dists_defects_facets < 2000]\n",
    "    inds_sub_facets = np.arange(mean_locs.shape[0])[dists_defects_facets < 2000]\n",
    "    # ranks_ep_facets = sizes_sub_facets**2 / dists_defects_sub_facets\n",
    "    #ranks_ep_facets_filt = ranks_ep_facets[ranks_ep_facets > 2e7]\n",
    "    mean_locs_send_facets = mean_locs_facets\n",
    "    final_mask_facets = np.full(mean_locs_send_facets.shape[0], True)\n",
    "    tips_hit_send_facets = tips_hit_sub_facets\n",
    "    uns, nums = np.unique(tips_hit_send_facets, return_counts=True)\n",
    "\n",
    "    for un, num in zip(uns, nums):\n",
    "        if num > 1:\n",
    "            final_mask_facets[np.argwhere(tips_hit_send_facets == un)[1:]] = False\n",
    "    facets_send_final = mean_locs_send_facets[final_mask_facets] / [4,4,40]\n",
    "    return facets_send_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIP FINDER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_locs_defects(root_id, soma_id = None, soma_table=None, center_collapse=True):\n",
    "    #print(\"START\", root_id)\n",
    "\n",
    "    mesh_obj = get_and_process_mesh(root_id)\n",
    "    if mesh_obj is None:\n",
    "        return None\n",
    "    # SKELETONIZE - if we are just looking for general errors, not errors at endpoints, this can be skipped\n",
    "    try:\n",
    "        if soma_table==None:\n",
    "            soma_table = get_soma(str(soma_id))\n",
    "        if soma_table[soma_table.id == soma_id].shape[0] > 0:\n",
    "            center = np.array(soma_table[soma_table.id == soma_id].pt_position)[0] * [4,4,40]\n",
    "        else:\n",
    "            center=None\n",
    "    except:\n",
    "        center = None\n",
    "    print(\"Subselecting largest connected component of mesh\")\n",
    "    mesh_obj, encapsulated_ids, max_verts = process_mesh_ccs(mesh_obj)\n",
    "    \n",
    "\n",
    "    skel_mp = skeletonize.skeletonize_mesh(trimesh_io.Mesh(mesh_obj.vertices, \n",
    "                                            mesh_obj.faces),\n",
    "                                            invalidation_d=4000,\n",
    "                                            shape_function='cone',\n",
    "                                            collapse_function='branch',\n",
    "#                                             soma_radius = soma_radius,\n",
    "                                            soma_pt=center,\n",
    "                                            smooth_neighborhood=5,\n",
    "                                             cc_vertex_thresh=max_verts - 10\n",
    "#                                                     collapse_params = {'dynamic_threshold':True}\n",
    "                                            )\n",
    "    print(\"Skel done\")\n",
    "\n",
    "    # find edges that only occur once..  might be faster to find these in the sparse matrix..\n",
    "    centers, lens = process_defects(mesh_obj)\n",
    "    eps, eps_nm = process_endpoints(mesh_obj, skel_mp)\n",
    "\n",
    "    if len(centers) !=0:\n",
    "        centers_errors, centers_errors_ep = process_mesh_errors(mesh_obj, centers, eps, eps_nm, lens, skel_mp)\n",
    "        # ranks_return = np.squeeze(ranks[np.argsort(ranks)[::-1]][:20])\n",
    "        # ranks_ep_return = np.squeeze(ranks_ep[np.argsort(ranks_ep)][::-1][:20])\n",
    "    else:\n",
    "        # Assign placeholder values for each of the variables above.\n",
    "        centers_errors = np.zeros ((1,3))\n",
    "        centers_errors_ep = np.zeros ((1,3))\n",
    "        ranks = np.zeros ((1))\n",
    "        ranks_ep = np.zeros((1, 3))\n",
    "        # path_to_root_dict = {}\n",
    "        # for ep in eps:\n",
    "        #     path_to_root_dict[ep] = skel_mp.path_to_root(ep)\n",
    "\n",
    "        ranks_return = 0\n",
    "        ranks_ep_return = 0\n",
    "\n",
    "\n",
    "    #if len(centers_errors.shape) > 1 and centers_errors.shape[0] > 0 and len(centers_errors_ep.shape) > 1 and len(centers_errors_ep.shape[0] > 0):\n",
    "    #    centers_errors = centers_errors[np.min(distance_matrix(centers_errors, centers_errors_ep), axis=1)>1000]\n",
    "    facets_send_final = process_mesh_facets(mesh_obj, skel_mp, eps, eps_nm)\n",
    "\n",
    "    errors_send = centers_errors / [4,4,40]\n",
    "    errors_tips_send = centers_errors_ep / [4,4,40]\n",
    "    encapsulated_centers = [e[0] for e in encapsulated_ids]\n",
    "    encapsulated_lens = [e[1] for e in encapsulated_ids]\n",
    "    sorted_encapsulated_send = np.array(encapsulated_centers)[np.argsort(encapsulated_lens)][::-1]\n",
    "\n",
    "\n",
    "\n",
    "    return sorted_encapsulated_send, facets_send_final, errors_send, errors_tips_send\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING TIP GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_endpoints(row):\n",
    "    seg_id = row[\"seg_id\"]\n",
    "    print(seg_id)\n",
    "    sorted_encapsulated_send, facets_send_final, errors_send, errors_tips_send = error_locs_defects(seg_id)\n",
    "    #facets_send_final = facets_send_final[facets_send_final != [0,0,0]]\n",
    "    #errors_tips_send = errors_tips_send[errors_tips_send != [0,0,0]]\n",
    "    together = np.vstack((facets_send_final, errors_tips_send))\n",
    "    #should alter \"together\" if not set together equal to this line\n",
    "    # print(together)\n",
    "    # new = together[together != [0,0,0]]\n",
    "    mask=np.sum(together,axis=1)\n",
    "    together = together[mask > 0]\n",
    "    return together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_endpoints(dataframe) :\n",
    "    dataframe[\"endpoints_generated\"] = dataframe.apply(find_endpoints, axis = 1)\n",
    "    return dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_eps_acc(gt_endpoints, pred_endpoints, threshold):\n",
    "    # Calculate distances\n",
    "    dist_matrix = np.array(spatial.distance.cdist(gt_endpoints, pred_endpoints, metric = 'euclidean'))\n",
    "\n",
    "    # Apply threshold\n",
    "    dist_matrix[dist_matrix > threshold] = 0\n",
    "\n",
    "    # Calculating accuracy\n",
    "    valid_eps = np.count_nonzero(dist_matrix, axis = 1)\n",
    "    accuracy = np.count_nonzero(valid_eps) / len(gt_endpoints)\n",
    "\n",
    "    #If more than one valid endpoint found for a single ground truth endpoint, add the other valid endpoints to extra_valid_pairs\n",
    "    # extra_valid_pairs = []\n",
    "    # [[extra_valid_pairs.append([gt_endpoints[i], pred_endpoints[index]]) \\\n",
    "    #     for index, j in enumerate(dist_matrix[i]) if j != np.min(dist_matrix[i][dist_matrix[i] != 0]) if j != 0] \\\n",
    "    #         for i in valid_eps if i > 1]\n",
    "\n",
    "    # return accuracy, extra_valid_pairs\n",
    "    return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864691135909994000\n",
      "Downloading Mesh\n",
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n",
      "Vertices:  7993\n",
      "Subselecting largest connected component of mesh\n",
      "Processing CC's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7992/7992 [00:00<00:00, 1160454.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skel done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 157589.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing facets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 14060.97it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 77672.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864691135247440303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Mesh\n",
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n",
      "Vertices:  21335\n",
      "Subselecting largest connected component of mesh\n",
      "Processing CC's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21334/21334 [00:00<00:00, 1076013.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skel done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 274364.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mesh errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 13957.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing facets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:00<00:00, 23288.61it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 103721.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864691135516937065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Mesh\n",
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n",
      "Vertices:  6056\n",
      "Subselecting largest connected component of mesh\n",
      "Processing CC's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6049/6049 [00:00<00:00, 1127515.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skel done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 225642.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mesh errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 41221.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing facets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 19519.74it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 105461.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864691134406233920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Mesh\n",
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n",
      "Vertices:  1180\n",
      "Subselecting largest connected component of mesh\n",
      "Processing CC's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1179/1179 [00:00<00:00, 382302.62it/s]\n",
      "rosetta error: thread_suspend failed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb Cell 24\u001b[0m in \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## TESTING ON THE 30 NEWLY LABELLED ORPHANS\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m##increase distance threshold\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m generate_endpoints(orphans)\n",
      "\u001b[1;32m/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb Cell 24\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_endpoints\u001b[39m(dataframe) :\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     dataframe[\u001b[39m\"\u001b[39m\u001b[39mendpoints_generated\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataframe\u001b[39m.\u001b[39;49mapply(find_endpoints, axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dataframe\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py:9555\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9544\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9546\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9547\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9548\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9553\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9554\u001b[0m )\n\u001b[0;32m-> 9555\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py:746\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    744\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 746\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 873\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    875\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/apply.py:889\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    887\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    888\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    890\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    891\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    892\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    893\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb Cell 24\u001b[0m in \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m seg_id \u001b[39m=\u001b[39m row[\u001b[39m\"\u001b[39m\u001b[39mseg_id\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(seg_id)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sorted_encapsulated_send, facets_send_final, errors_send, errors_tips_send \u001b[39m=\u001b[39m error_locs_defects(seg_id)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#facets_send_final = facets_send_final[facets_send_final != [0,0,0]]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#errors_tips_send = errors_tips_send[errors_tips_send != [0,0,0]]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m together \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack((facets_send_final, errors_tips_send))\n",
      "\u001b[1;32m/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb Cell 24\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSubselecting largest connected component of mesh\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     mesh_obj, encapsulated_ids, max_verts \u001b[39m=\u001b[39m process_mesh_ccs(mesh_obj)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     skel_mp \u001b[39m=\u001b[39m skeletonize\u001b[39m.\u001b[39;49mskeletonize_mesh(trimesh_io\u001b[39m.\u001b[39;49mMesh(mesh_obj\u001b[39m.\u001b[39;49mvertices, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                                             mesh_obj\u001b[39m.\u001b[39;49mfaces),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m                                             invalidation_d\u001b[39m=\u001b[39;49m\u001b[39m4000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                                             shape_function\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcone\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                                             collapse_function\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbranch\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m#                                             soma_radius = soma_radius,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                                             soma_pt\u001b[39m=\u001b[39;49mcenter,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                                             smooth_neighborhood\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                                              cc_vertex_thresh\u001b[39m=\u001b[39;49mmax_verts \u001b[39m-\u001b[39;49m \u001b[39m10\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#                                                     collapse_params = {'dynamic_threshold':True}\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m                                             )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSkel done\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X32sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m# find edges that only occur once..  might be faster to find these in the sparse matrix..\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/meshparty/skeletonize.py:223\u001b[0m, in \u001b[0;36mskeletonize_mesh\u001b[0;34m(mesh, soma_pt, soma_radius, collapse_soma, collapse_function, invalidation_d, smooth_vertices, compute_radius, shape_function, compute_original_index, verbose, smooth_iterations, smooth_neighborhood, smooth_r, cc_vertex_thresh, root_index, remove_zero_length_edges, collapse_params, meta)\u001b[0m\n\u001b[1;32m    221\u001b[0m         rs \u001b[39m=\u001b[39m ray_trace_distance(orig_skel_index[vert_filter], mesh)\n\u001b[1;32m    222\u001b[0m     \u001b[39melif\u001b[39;00m shape_function \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcone\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 223\u001b[0m         rs \u001b[39m=\u001b[39m shape_diameter_function(orig_skel_index[vert_filter], mesh)\n\u001b[1;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     rs \u001b[39m=\u001b[39m rs[vert_filter]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/meshparty/ray_tracing.py:227\u001b[0m, in \u001b[0;36mshape_diameter_function\u001b[0;34m(mesh_inds, mesh, num_points, cone_angle)\u001b[0m\n\u001b[1;32m    224\u001b[0m     weights \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39mangles\n\u001b[1;32m    225\u001b[0m good_rows \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misfinite(weights)\n\u001b[0;32m--> 227\u001b[0m rs \u001b[39m=\u001b[39m all_angle_weighted_distances(\n\u001b[1;32m    228\u001b[0m     ds[good_rows], angles[good_rows], weights[good_rows], rep_inds[hit_rows[good_rows]], mesh_inds)\n\u001b[1;32m    229\u001b[0m \u001b[39mreturn\u001b[39;00m rs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/meshparty/ray_tracing.py:177\u001b[0m, in \u001b[0;36mall_angle_weighted_distances\u001b[0;34m(ds, angles, weights, rep_inds, inds)\u001b[0m\n\u001b[1;32m    174\u001b[0m data\u001b[39m.\u001b[39mappend((ds[row], angles[row], weights[row]))\n\u001b[1;32m    175\u001b[0m ind_map\u001b[39m.\u001b[39mappend(real_inds[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 177\u001b[0m rs \u001b[39m=\u001b[39m mu\u001b[39m.\u001b[39;49mmultiprocess_func(_multi_angle_weighted_distance, data)\n\u001b[1;32m    179\u001b[0m rs_out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(inds))\n\u001b[1;32m    180\u001b[0m rs_out[np\u001b[39m.\u001b[39marray(ind_map)] \u001b[39m=\u001b[39m rs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/multiwrapper/multiprocessing_utils.py:58\u001b[0m, in \u001b[0;36mmultiprocess_func\u001b[0;34m(func, params, debug, verbose, n_threads)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m debug:\n\u001b[1;32m     57\u001b[0m     pool \u001b[39m=\u001b[39m Pool(n_threads)\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mmap(func, params)\n\u001b[1;32m     59\u001b[0m     pool\u001b[39m.\u001b[39mclose()\n\u001b[1;32m     60\u001b[0m     pool\u001b[39m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## TESTING ON THE 30 NEWLY LABELLED ORPHANS\n",
    "\n",
    "##increase distance threshold\n",
    "generate_endpoints(orphans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864691134472630080\n",
      "864691134742288112\n",
      "864691136584897745\n"
     ]
    }
   ],
   "source": [
    "#apply function to entire df \n",
    "count = 0\n",
    "acc_array = []\n",
    "for index, row in orphans.iterrows():\n",
    "    if (type(row[\"real_endpoints\"])== list and type(row[\"endpoints_generated\"]) == list):\n",
    "        acc = 1\n",
    "        print(\"both empty\")\n",
    "    elif(type(row[\"endpoints_generated\"]) == list and type(row[\"real_endpoints\"]) != list):\n",
    "        acc = 0\n",
    "        print(\"no endpoints generated, but endpoints exist\")\n",
    "    else:\n",
    "        count = count + 1\n",
    "        # print(\"predicted,\", row[\"endpoints_generated\"])\n",
    "        # print()\n",
    "        # print(\"real,\", row[\"real_endpoints\"])\n",
    "        # print()\n",
    "        # print(\"seg_id\", row[\"seg_id\"])\n",
    "        # print()\n",
    "        # print(type(row[\"real_endpoints\"]))\n",
    "\n",
    "        #print(str(count) + ':')\n",
    "        acc = pred_eps_acc(row[\"real_endpoints\"], row[\"endpoints_generated\"], 250)\n",
    "        acc_array.append(acc)\n",
    "        if(acc == 0.0):\n",
    "            print(row[\"seg_id\"])\n",
    "        #print(acc)\n",
    "        # print(\"NEXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         1.         0.5        1.\n",
      " 0.5        1.         0.         1.         0.         0.75\n",
      " 1.         1.         0.5        1.         1.         0.\n",
      " 1.         0.5        0.66666667 1.         0.66666667 0.5\n",
      " 0.33333333]\n",
      "\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "acc_array = np.array(acc_array)\n",
    "print(acc_array)\n",
    "print()\n",
    "print(len(acc_array[acc_array > 0.3]))\n",
    "\n",
    "\n",
    "###SEVENTY PERCENT OF ORPHANS HAD SOME ENDPOINT FOUND\n",
    "\n",
    "\n",
    "# print(len(acc_array))\n",
    "# print(acc_array)\n",
    "# print(acc_array[])\n",
    "\n",
    "#smaller mesh volume smaller threshold \n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Possiby search the 6 perfect ones dependent on task \n",
    "--changing invalidation_d resulted in the biggest change in accuracies \n",
    "--eps_nm? \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINE TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864691135516937065\n",
      "[[ 77266.35       113085.          20442.45      ]\n",
      " [ 79721.25       109333.          20410.425     ]\n",
      " [ 79184.6637931  109173.56896552  20430.44741379]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# indices 2, 5 11\n",
    "\n",
    "print(orphans[\"seg_id\"][2])\n",
    "print(orphans[\"endpoints_generated\"][2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES FOR SMALL PROCESSES: \n",
    "\n",
    "1. index 2 was very small process with two clear flat ends. Skeleton did not reach one flat end and resulted in zero eps_nm and 1 error location which was rightfully filtered out. Changing threshold for eps_nm (not sure if we shoudl do this) found 2 endpoints, but these locations are not correct. They represent the ends of the skeleton. Increasing inval_d did not find the correct endpoints (as exepcted). Decreasing invalidation_d from 5000 to 1500 found one of the flat regions, but endpoint filtered out before getting facets. Endpoint not found if eps_nm threshold returned to 3000. \n",
    "\n",
    "2. index 5 also somewhat small, but has 2 flat ends. Skeleton did reach both ends (somewhat), but resulted in zero eps_nm with threshold of 3000. Changed eps_nm threshold to 1500 (not sure if we should do this) and found 2 endpoints (ends of the skeleton). Left invalidation_d quite low at 1500. AFter filtering and scaling, the two endpoints in ep_nm were gone. We should focus on translation from eps_nm to facets. \n",
    "\n",
    "3. Index 11 was VERY VERY small and flat. Resonable that skeleton wasn't albe to be processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Mesh\n",
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n",
      "Vertices:  806\n",
      "Processing CC's\n"
     ]
    }
   ],
   "source": [
    "#starting with Y shaped ONE!!! \n",
    "mesh_obj = get_and_process_mesh(864691133906162903)\n",
    "print(\"Processing CC's\")\n",
    "ccs_graph = trimesh.graph.connected_components(mesh_obj.edges)\n",
    "ccs_len = [len(c) for c in ccs_graph]\n",
    "\n",
    "# Subselect the parts of the mesh that are not inside one another \n",
    "# the other components are an artifact of the soma seg and small unfilled sections\n",
    "largest_component = ccs_graph[np.argmax(ccs_len)]\n",
    "largest_component_remap = np.arange(ccs_graph[np.argmax(ccs_len)].shape[0])\n",
    "face_dict = {largest_component[i]:largest_component_remap[i] for i in range(largest_component.shape[0])}\n",
    "\n",
    "new_faces_mask = np.isin(mesh_obj.faces, list(face_dict.keys()))\n",
    "new_faces_mask = new_faces_mask[:, 0]*new_faces_mask[:, 1]*new_faces_mask[:, 2]\n",
    "\n",
    "new_faces = np.vectorize(face_dict.get)(mesh_obj.faces[new_faces_mask])\n",
    "new_faces = new_faces[new_faces[:, 0] != None]\n",
    "largest_component_mesh = trimesh.Trimesh(mesh_obj.vertices[largest_component], new_faces)\n",
    "\n",
    "all_ids = set(largest_component)\n",
    "encapsulated_ids = []\n",
    "\n",
    "for i in range(1, len(ccs_graph)):\n",
    "    n_con = largest_component_mesh.contains(mesh_obj.vertices[ccs_graph[i]])\n",
    "    if np.sum(n_con) / n_con.shape[0] == 0 and n_con.shape[0] > 50:\n",
    "        all_ids.update(ccs_graph[i])\n",
    "    else:\n",
    "        if len(ccs_graph[i]) < 1000:\n",
    "            encapsulated_ids.append((np.mean(mesh_obj.vertices[ccs_graph[i]], axis=0)/[4,4,40], len(ccs_graph[i])))\n",
    "        \n",
    "all_component = np.array(list(ccs_graph[np.argmax(ccs_len)]))\n",
    "all_component_remap = np.arange(all_component.shape[0])\n",
    "face_dict = {all_component[i]:all_component_remap[i] for i in range(all_component.shape[0])}\n",
    "new_faces_mask = np.isin(mesh_obj.faces, list(face_dict.keys()))\n",
    "new_faces_mask = new_faces_mask[:, 0]*new_faces_mask[:, 1]*new_faces_mask[:, 2]\n",
    "\n",
    "new_faces = np.vectorize(face_dict.get)(mesh_obj.faces[new_faces_mask])\n",
    "new_faces[new_faces[:, 0] != None]\n",
    "\n",
    "largest_component_mesh = trimesh.Trimesh(mesh_obj.vertices[all_component], new_faces)\n",
    "\n",
    "mesh_obj = largest_component_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 805/805 [00:00<00:00, 278743.06it/s]\n"
     ]
    }
   ],
   "source": [
    "skel_mp = skeletonize.skeletonize_mesh(trimesh_io.Mesh(mesh_obj.vertices, \n",
    "                                            mesh_obj.faces),\n",
    "                                            invalidation_d=5000,\n",
    "                                            shape_function='cone',\n",
    "                                            collapse_function='branch',\n",
    "                                            #soma_radius = soma_radius,\n",
    "                                            #soma_pt=center,\n",
    "                                            smooth_neighborhood=5,\n",
    "                                            #cc_vertex_thresh=max_verts - 10\n",
    "                                            #collapse_params = {'dynamic_threshold':True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meshparty import trimesh_io, trimesh_vtk, skeletonize, mesh_filters\n",
    "skel_actor = trimesh_vtk.skeleton_actor(skel_mp,\n",
    "                   edge_property=None,\n",
    "                   vertex_property=None,\n",
    "                   vertex_data=None,\n",
    "                   normalize_property=True,\n",
    "                   color=(1, 0, 1),\n",
    "                   line_width=5,\n",
    "                   opacity=0.7,\n",
    "                   lut_map=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 17633.71it/s]\n"
     ]
    }
   ],
   "source": [
    "#original = 20\n",
    "size_cc_threshold = 20\n",
    "# a is the threshold for the 'jaggedness' of the mesh\n",
    "# Turn a lower to get more error locations, but these locations will be less jagged\n",
    "#original: 0.75\n",
    "a = 0.75\n",
    "\n",
    "# Removing 'broken' edges - edges in the mesh with only 1 vertex\n",
    "bad_edges = trimesh.grouping.group_rows(\n",
    "mesh_obj.edges_sorted, require_count=1)\n",
    "bad_edges_ind = mesh_obj.edges[bad_edges]\n",
    "sparse_edges = mesh_obj.edges_sparse\n",
    "xs = list(bad_edges_ind[:, 0]) + list(bad_edges_ind[:, 1]) \n",
    "ys = list(bad_edges_ind[:, 1]) + list(bad_edges_ind[:, 0])\n",
    "vs = [1]*bad_edges_ind.shape[0]*2\n",
    "\n",
    "# This averages the jaggedness around each vertex so we can find regions that are gereraly jagged\n",
    "bad_inds = scipy.sparse.coo_matrix((vs, (xs, ys)), shape=(mesh_obj.vertices.shape[0], mesh_obj.vertices.shape[0]))\n",
    "# Make it symmetrical and add identity so each integrates from itself too, then subtract singleton edges\n",
    "# I noticed that the number of asymmetrical edges vs the number of single edges I find from group rows\n",
    "# Are close but different. Haven't looked into that yet. Also removing edges 1 hop away from single edges to remove bias towards\n",
    "# Holes in the mesh that are caused by mesh construction errors as opposed to segmentation errors\n",
    "sparse_edges = mesh_obj.edges_sparse + mesh_obj.edges_sparse.T + identity(mesh_obj.edges_sparse.shape[0]) - sparse_edges.multiply(bad_inds) - bad_inds\n",
    "degs = mesh_obj.vertex_degree + 1\n",
    "\n",
    "# N_iter is a smoothing parameter here. The loop below smooths the vertex error about the mesh to get more consistent connected regions\n",
    "n_iter = 2\n",
    "angle_sum = np.array(abs(mesh_obj.face_angles_sparse).sum(axis=1)).flatten()\n",
    "defs = (2 * np.pi) - angle_sum\n",
    "\n",
    "abs_defs = np.abs(defs)\n",
    "abs_defs_i = abs_defs.copy()\n",
    "for i in range(n_iter):\n",
    "    abs_defs_i = sparse_edges.dot(abs_defs_i) / degs\n",
    "\n",
    "# Here we are thresholding the error regions to pick only the jagged ones\n",
    "verts_select = np.argwhere((abs_defs_i > a))# & (abs_defs < 2.5))\n",
    "\n",
    "edges_mask = np.isin(mesh_obj.edges, verts_select)\n",
    "edges_mask[bad_edges] = False\n",
    "edges_select = edges_mask[:, 0] * edges_mask[:, 1]\n",
    "edges_select = mesh_obj.edges[edges_select]\n",
    "\n",
    "G = nx.from_edgelist(edges_select)#f_edge_sub)\n",
    "\n",
    "ccs = nx.connected_components(G)\n",
    "subgraphs = [G.subgraph(cc).copy() for cc in ccs]\n",
    "\n",
    "lens = []\n",
    "lengths = []\n",
    "for i in tqdm(range(len(subgraphs))):\n",
    "    ns = np.array(list(subgraphs[i].nodes()))\n",
    "#     ns = ns[abs_defs[ns ]]\n",
    "    l = len(ns)\n",
    "    #manip above 20 (ccs that have jaggedness)\n",
    "    if l > size_cc_threshold and l < 5000:\n",
    "        lens.append(ns)\n",
    "        lengths.append(l)\n",
    "all_nodes = set()\n",
    "for l in lens:\n",
    "    all_nodes.update(l)\n",
    "all_nodes = np.array(list(all_nodes))\n",
    "# sharp_pts = mesh_obj.vertices[all_nodes]\n",
    "centers = np.array([np.mean(mesh_obj.vertices[list(ppts)],axis=0) for ppts in lens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28 30]\n",
      "\n",
      "[[489195. 942627. 851130.]\n",
      " [489321. 943971. 846426.]]\n",
      "(2, 3)\n",
      "2\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "interior_cc_mask = set()\n",
    "el = nx.from_edgelist(skel_mp.edges)\n",
    "comps = list(nx.connected_components(el))\n",
    "for c in comps:\n",
    "    if len(c) < 100:\n",
    "        n_con = mesh_obj.contains(skel_mp.vertices[list(c)])\n",
    "        if np.sum(n_con) / n_con.shape[0] > .10:\n",
    "            interior_cc_mask.update(list(c))\n",
    "# Process the skeleton to get the endpoints\n",
    "edges = skel_mp.edges.copy()\n",
    "\n",
    "edge_mask = ~np.isin(edges, interior_cc_mask)\n",
    "edge_mask = edge_mask[:, 0] + edge_mask[:, 1]\n",
    "edges = edges[edge_mask]\n",
    "edges_flat  = edges.flatten()\n",
    "edge_bins = np.bincount(edges_flat) \n",
    "\n",
    "eps = np.squeeze(np.argwhere(edge_bins==1))\n",
    "eps_nm = skel_mp.vertices[eps]\n",
    "print(eps)\n",
    "\n",
    "eps_comp = distance_matrix(eps_nm, eps_nm)\n",
    "eps_comp[eps_comp == 0] = np.inf\n",
    "#MODIFIED (actually changed back to 3000)\n",
    "eps_thresh = np.argwhere(~(np.min(eps_comp, axis=0) < 3000))\n",
    "\n",
    "eps = np.squeeze(eps[eps_thresh])\n",
    "eps_nm = np.squeeze(eps_nm[eps_thresh])\n",
    "print()\n",
    "print(eps_nm)\n",
    "print(eps_nm.shape)\n",
    "print(len(eps))\n",
    "print(eps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8],\n",
       "       [ 87],\n",
       "       [ 89],\n",
       "       [133],\n",
       "       [160],\n",
       "       [192],\n",
       "       [216],\n",
       "       [220],\n",
       "       [221],\n",
       "       [229],\n",
       "       [236],\n",
       "       [238],\n",
       "       [240]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 30])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numbers import Number\n",
    "isinstance(eps, Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing facets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb Cell 41\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X54sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mprint\u001b[39m(mean_locs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X54sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m#distance from every facet to each skel endpoint\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X54sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m dist_matrix_facets \u001b[39m=\u001b[39m distance_matrix(mean_locs, eps_nm)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X54sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mprint\u001b[39m(dist_matrix_facets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#X54sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m#represents index of the current facet\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/scipy/spatial/_kdtree.py:884\u001b[0m, in \u001b[0;36mdistance_matrix\u001b[0;34m(x, y, p, threshold)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[39m\"\"\"Compute the distance matrix.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m \n\u001b[1;32m    854\u001b[0m \u001b[39mReturns the matrix of all pair-wise distances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    880\u001b[0m \n\u001b[1;32m    881\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    883\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\n\u001b[0;32m--> 884\u001b[0m m, k \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[1;32m    885\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(y)\n\u001b[1;32m    886\u001b[0m n, kk \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "#are of flat region\n",
    "#try to decrease/increase\n",
    "facet_area_threshold = 30000\n",
    "#threshold distance from tip to jagged error or a facet\n",
    "#try increasing to get more\n",
    "#this threshold impacts the facets\n",
    "error_distance_threshold = 2000\n",
    "\n",
    "\n",
    "if eps.size == 1:\n",
    "        print(\"hello there\")\n",
    "        #eps_nm should therefore be reshaped\n",
    "        eps_nm = eps_nm.reshape((1,3))\n",
    "\n",
    "\n",
    "# path_to_root_dict = {}\n",
    "# for ep in eps:\n",
    "#     #doesn't make sense for orphans to include \n",
    "#     path_to_root_dict[ep] = skel_mp.path_to_root(ep)\n",
    "\n",
    "\n",
    "print(\"Processing facets\")\n",
    "#can possibly change param here\n",
    "#th\n",
    "# reshold on size of flat area\n",
    "locs = np.argwhere(mesh_obj.facets_area > facet_area_threshold)\n",
    "\n",
    "mesh_map = skel_mp.mesh_to_skel_map\n",
    "mesh_coords = mesh_obj.vertices[mesh_obj.faces]\n",
    "mean_locs = []\n",
    "mesh_ind = []\n",
    "fs = []\n",
    "for l in tqdm(locs):\n",
    "    #mesh coords is each vertex coordinate \n",
    "    #need to index normal vector\n",
    "    fs.append(np.sum(mesh_obj.facets_area[l]))\n",
    "    fc = mesh_obj.facets[l[0]]\n",
    "    # print(np.sum(mesh_obj.facets_area[l]))\n",
    "    vert_locs = mesh_coords[fc]\n",
    "    mean_locs.append(np.mean(vert_locs[:, 0], axis=0))\n",
    "    mesh_ind.append(fc[0])\n",
    "mesh_ind = mesh_obj.faces[mesh_ind][:, 0]\n",
    "mean_locs = np.array(mean_locs)\n",
    "dists_defects_facets = np.zeros(mean_locs.shape[0])\n",
    "mesh_map_facets = skel_mp.mesh_to_skel_map\n",
    "closest_skel_pts_facets = mesh_map[[m for m in mesh_ind]]\n",
    "print(mean_locs)\n",
    "#distance from every facet to each skel endpoint\n",
    "dist_matrix_facets = distance_matrix(mean_locs, eps_nm)\n",
    "print(dist_matrix_facets)\n",
    "#represents index of the current facet\n",
    "ct = 0\n",
    "\n",
    "closest_tip_facets = np.zeros((mean_locs.shape[0]))\n",
    "\n",
    "for center in tqdm(mean_locs):\n",
    "    #mapping current facet to closet point on skeleton \n",
    "    #checking if the skel point in in path from ep to some\n",
    "    #doesn't make sense for orphans\n",
    "    closest_skel_pt = closest_skel_pts_facets[ct]\n",
    "    eps_hit = []\n",
    "    if eps.size == 1:\n",
    "        eps_hit.append(eps)\n",
    "    else:\n",
    "        for j, ep in enumerate(eps):\n",
    "            # if closest_skel_pt in path_to_root_dict[ep]:\n",
    "            #     eps_hit.append(j)\n",
    "            eps_hit.append(j)\n",
    "\n",
    "\n",
    "    #distance from every error(facets and jagged) to every endpoint\n",
    "    if(eps.size == 1):\n",
    "         dists = dist_matrix_facets[ct]\n",
    "    else:\n",
    "         dists = dist_matrix_facets[ct, eps_hit]\n",
    "    \n",
    "    #index of closest endpoint for current facet\n",
    "    amin = np.argmin(dists)\n",
    "    # print(amin)\n",
    "    #The code retrieves the index of the closest endpoint in the original eps array\n",
    "    tip_hit = eps_hit[amin]\n",
    "    # print(tip_hit)\n",
    "    # print()\n",
    "    min_dist = dists[amin]\n",
    "    # print(min_dist)\n",
    "    # print()\n",
    "    \n",
    "\n",
    "    closest_tip_facets[ct] = tip_hit\n",
    "    dists_defects_facets[ct] = min_dist\n",
    "    ct+=1\n",
    "\n",
    "#printing out closest_tip_facets\n",
    "print(closest_tip_facets)\n",
    "print(dists_defects_facets)\n",
    "\n",
    "#filtered distances\n",
    "dists_defects_sub_facets = dists_defects_facets[dists_defects_facets < error_distance_threshold]\n",
    "sizes_sub_facets = np.array(fs)[dists_defects_facets < error_distance_threshold]\n",
    "#look at mean locs: getting vector of booleans: see if anything getting filtered\n",
    "#if large distance set threshold below distance\n",
    "mean_locs_facets = mean_locs[dists_defects_facets < error_distance_threshold]\n",
    "\n",
    "\n",
    "\n",
    "#ADDED//\n",
    "#change back to np.inf???\n",
    "tips_hit_sub_facets = closest_tip_facets[dists_defects_facets < error_distance_threshold]\n",
    "closest_skel_pts_sub_facets = closest_skel_pts_facets[dists_defects_facets < error_distance_threshold]\n",
    "inds_sub_facets = np.arange(mean_locs.shape[0])[dists_defects_facets < error_distance_threshold]\n",
    "#END\n",
    "\n",
    "#change rank function, possibly change sizes, add a threshold for all\n",
    "\n",
    "#NEW CODE!!!!! \n",
    "ranks_ep_facets = 1 / dists_defects_sub_facets\n",
    "#(no longer including ranking)\n",
    "mean_locs_send_facets = mean_locs_facets\n",
    "#mean_locs_send_facets = mean_locs_facets[np.argsort(ranks_ep_facets)][::-1][:20]\n",
    "final_mask_facets = np.full(mean_locs_send_facets.shape[0], True)\n",
    "\n",
    "\n",
    "#OLD code\n",
    "# ranks_ep_facets = sizes_sub_facets**2 / dists_defects_sub_facets\n",
    "# mean_locs_send_facets = mean_locs_facets[np.argsort(ranks_ep_facets)][::-1][:20]\n",
    "# final_mask_facets = np.full(mean_locs_send_facets.shape[0], True)\n",
    "# tips_hit_send_facets = tips_hit_sub_facets[np.argsort(ranks_ep_facets)][::-1][:20]\n",
    "# uns, nums = np.unique(tips_hit_send_facets, return_counts=True)\n",
    "# for un, num in zip(uns, nums):\n",
    "#         if num > 1:\n",
    "#             final_mask_facets[np.argwhere(tips_hit_send_facets == un)[1:]] = False\n",
    "\n",
    "\n",
    "#ADDED in this as well: this code is filtering out duplicates, comment out for now\n",
    "#tips_hit_send_facets = tips_hit_sub_facets\n",
    "# got rid of ranking\n",
    "# HELPS \n",
    "tips_hit_send_facets = tips_hit_sub_facets\n",
    "uns, nums = np.unique(tips_hit_send_facets, return_counts=True)\n",
    "for un, num in zip(uns, nums):\n",
    "    if num > 1:\n",
    "        final_mask_facets[np.argwhere(tips_hit_send_facets == un)[1:]] = False\n",
    "# #END\n",
    "\n",
    "\n",
    "# This is the merged facets variable!!\n",
    "facets_send_final = mean_locs_send_facets[final_mask_facets] / [4,4,40]\n",
    "#facets_send_final = mean_locs_send_facets/ [4,4,40]\n",
    "print(facets_send_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_locs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrackedArray([[489195., 942627., 851130.],\n",
       "              [489321., 943971., 846426.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8],\n",
       "       [ 87],\n",
       "       [ 89],\n",
       "       [133],\n",
       "       [160],\n",
       "       [192],\n",
       "       [216],\n",
       "       [220],\n",
       "       [221],\n",
       "       [229],\n",
       "       [236],\n",
       "       [238],\n",
       "       [240]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([124, 235, 248])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4687.89430342, 14125.77452744, 14032.53407265, ...,\n",
       "       14850.63816811, 12728.02706628,  7056.        ])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_obj.facets_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[400170.75      , 690637.5       , 752535.        ],\n",
       "       [403739.        , 697606.        , 748377.        ],\n",
       "       [403710.17647059, 697547.11764706, 748545.        ],\n",
       "       [407671.6       , 697635.4       , 747894.        ],\n",
       "       [405925.96153846, 699199.84615385, 745416.        ],\n",
       "       [406419.77419355, 697145.12903226, 746697.        ],\n",
       "       [406735.        , 697083.8       , 746025.        ],\n",
       "       [406486.5       , 697404.75      , 745983.        ],\n",
       "       [406105.875     , 697719.75      , 746613.        ],\n",
       "       [405065.5       , 697917.5       , 747789.        ],\n",
       "       [403350.        , 695589.        , 749133.        ],\n",
       "       [403086.        , 695520.        , 749217.        ],\n",
       "       [403368.        , 695486.4       , 749427.        ],\n",
       "       [400943.66666667, 694288.        , 750855.        ],\n",
       "       [400816.5       , 694540.        , 750183.        ],\n",
       "       [401236.5       , 695131.5       , 749658.        ],\n",
       "       [401608.2       , 695101.26      , 749742.        ],\n",
       "       [401671.06451613, 695069.51612903, 749658.        ],\n",
       "       [402213.        , 695025.54545455, 749574.        ],\n",
       "       [402334.8       , 695068.5       , 749658.        ],\n",
       "       [402958.5       , 694442.        , 749868.        ],\n",
       "       [401427.25      , 689669.75      , 752430.        ],\n",
       "       [401268.        , 689493.        , 752577.        ],\n",
       "       [407797.09090909, 700560.        , 743463.        ],\n",
       "       [408747.5       , 698638.5       , 745857.        ],\n",
       "       [408740.85      , 698859.        , 745542.        ],\n",
       "       [408571.8       , 698724.6       , 745941.        ],\n",
       "       [412148.33333333, 702415.        , 737310.        ],\n",
       "       [410536.        , 703066.        , 740544.        ],\n",
       "       [410819.5       , 702803.5       , 740064.5       ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([272, 364, 364, 314,  53,  43,  43,  43,  43, 314, 214, 220, 213,\n",
       "       175, 175, 175, 175, 175, 175, 175, 169, 262, 228,   1,  64,  64,\n",
       "        64,  85, 135, 114])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_skel_pts_facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 30 is out of bounds for axis 0 with size 30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb Cell 45\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#Y124sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dists \u001b[39m=\u001b[39m dist_matrix_facets[ct, eps_hit]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sheeltanna/Desktop/AGT_REPO/campfire/Tip_Finder_2023.ipynb#Y124sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dist_matrix_facets\n",
      "\u001b[0;31mIndexError\u001b[0m: index 30 is out of bounds for axis 0 with size 30"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dists = dist_matrix_facets[ct, eps_hit]\n",
    "dist_matrix_facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 63, 103])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrackedArray([[351109.5  , 143466.75 ,  15149.4  ],\n",
       "              [348705.   , 145225.5  ,  14892.675]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_nm / [4,4,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3026.55173589,  4811.43914125,   519.60043303, 11271.84091486,\n",
       "        8842.88555902])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2477.23484515, 17655.92736133],\n",
       "       [ 2404.4789082 , 17977.80085606],\n",
       "       [ 4223.00943451, 14810.92911046],\n",
       "       [ 3620.90893407, 15574.12721114],\n",
       "       [ 2638.25908508, 16414.83356602],\n",
       "       [ 2584.10718458, 16757.06704845],\n",
       "       [ 2559.96050995, 17998.55364502],\n",
       "       [ 2268.72245009, 18801.92297494],\n",
       "       [17985.97664738,   459.49228503],\n",
       "       [ 6628.9186901 , 11895.14224379],\n",
       "       [ 6614.21024092, 11942.49601679],\n",
       "       [ 6213.394161  , 12347.27180392],\n",
       "       [ 6618.2156793 , 11927.30869802],\n",
       "       [ 6329.24365545, 12227.14317615],\n",
       "       [ 7276.96241573, 11234.25297917],\n",
       "       [ 8063.81361392, 10455.00645624],\n",
       "       [ 9511.28372608,  9050.42767507],\n",
       "       [ 9474.39807439,  9030.37112978],\n",
       "       [11035.44902802,  7526.92302671],\n",
       "       [12115.54137668,  6379.22658713],\n",
       "       [13902.89054214,  4828.81339784],\n",
       "       [12993.197622  ,  5576.87461258],\n",
       "       [13409.35896963,  5198.84127395],\n",
       "       [16699.83913096,  1984.85490654],\n",
       "       [16268.75109712,  2197.15203388],\n",
       "       [16125.57229992,  2374.06318366]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix_facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40,  40,  12,  87,  89,  88,  36,  40, 128,  21,  21,  32,  32,\n",
       "        31,  26, 159, 174, 174, 166, 106, 111, 113, 110, 149, 132, 132])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_skel_pts_facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_tip_facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40,  40,  12,  87,  89,  88,  36,  40, 128,  21,  21,  32,  32,\n",
       "        31,  26, 159, 174, 174, 166, 106, 111, 113, 110, 149, 132, 132])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_skel_pts_facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16125.57229992])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[316822.08510638, 436990.78723404, 817341.        ],\n",
       "       [316950.9       , 436697.1       , 817257.        ],\n",
       "       [315507.24861878, 439514.56906077, 817341.        ],\n",
       "       [315775.32      , 438889.92      , 816018.        ],\n",
       "       [316641.        , 438390.        , 816018.        ],\n",
       "       [316529.0625    , 437897.25      , 816459.        ],\n",
       "       [316685.25      , 436621.5       , 816018.        ],\n",
       "       [317531.66666667, 436067.33333333, 817341.        ],\n",
       "       [309065.4       , 452340.        , 817698.        ],\n",
       "       [314727.        , 442428.        , 816942.        ],\n",
       "       [314736.33333333, 442358.        , 817341.        ],\n",
       "       [314839.        , 441980.        , 816816.        ],\n",
       "       [314650.        , 442360.33333333, 816774.        ],\n",
       "       [314867.        , 442179.5       , 816375.        ],\n",
       "       [314433.        , 443052.        , 816627.        ],\n",
       "       [314067.        , 443772.        , 816417.        ],\n",
       "       [313703.73770492, 445291.        , 816018.        ],\n",
       "       [313618.10869565, 445196.34782609, 816333.        ],\n",
       "       [313026.        , 446677.5       , 816144.        ],\n",
       "       [312282.6       , 447482.7       , 816585.        ],\n",
       "       [311714.54198473, 449239.53435115, 816018.        ],\n",
       "       [312120.66666667, 448427.        , 816375.        ],\n",
       "       [311995.38461538, 448839.46153846, 816333.        ],\n",
       "       [309547.        , 451164.        , 816690.        ],\n",
       "       [309899.1       , 450859.5       , 817257.        ],\n",
       "       [309701.        , 450534.        , 817425.        ]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 3)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_defects_facets.shape\n",
    "mean_locs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers <class 'numpy.ndarray'>\n",
      "eps_nm <class 'trimesh.caching.TrackedArray'>\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 5410.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[402859.3902439  694017.73170732 741139.17073171]\n",
      " [410665.5        702794.02941176 739061.64705882]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# skel Distance threshold to the defects (the jagged ones)\n",
    "#BUT this impacts the center_errors\n",
    "#try to increase to get more points if not finding flat regions\n",
    "error_distance_threshold_defects = 10000 #1000\n",
    "\n",
    "\n",
    "dists_defects = np.zeros(centers.shape[0])\n",
    "\n",
    "\n",
    "sizes = np.zeros(centers.shape[0])\n",
    "mesh_map = skel_mp.mesh_to_skel_map\n",
    "closest_skel_pts = mesh_map[[l[0] for l in lens]]\n",
    "\n",
    "# print(centers, eps_nm)\n",
    "\n",
    "print(\"centers \" + str(type(centers)))\n",
    "print(\"eps_nm \" + str(type(eps_nm)))\n",
    "print(len(centers))\n",
    "\n",
    "if len(centers) == 0:\n",
    "    centers_errors_ep = [0,0,0]\n",
    "    \n",
    "\n",
    "else:\n",
    "    #distance matrix of center and endpoints before merging right???\n",
    "    dist_matrix = distance_matrix(centers, eps_nm)\n",
    "    ct = 0\n",
    "\n",
    "    closest_tip = np.zeros((centers.shape[0]))\n",
    "\n",
    "    for center in tqdm(centers):\n",
    "    #     skel_pts_dists = np.linalg.norm(skel_mp.vertices - center, axis=1)\n",
    "    #     ep_pts_dists = np.linalg.norm(eps_nm - center, axis=1)\n",
    "        \n",
    "        closest_skel_pt = closest_skel_pts[ct]\n",
    "        min_ep = np.inf\n",
    "        eps_hit = []\n",
    "        for j, ep in enumerate(eps):\n",
    "            #path to root doesn't make sense, let us compare all eps\n",
    "            # if closest_skel_pt in path_to_root_dict[ep]:\n",
    "            #     eps_hit.append(j)\n",
    "            eps_hit.append(j)\n",
    "        #doesn't make sense anymore\n",
    "        if len(eps_hit) == 0:\n",
    "            dists_defects[ct] = np.inf\n",
    "            sizes[ct] = np.inf\n",
    "            ct+=1\n",
    "            continue\n",
    "        \n",
    "        dists = dist_matrix[ct, eps_hit]\n",
    "        #print(dists)\n",
    "    #     print(dists, eps_hit, center / [4,4,40])\n",
    "        \n",
    "        amin = np.argmin(dists)\n",
    "        tip_hit = eps_hit[amin]\n",
    "        min_dist = dists[amin]\n",
    "        \n",
    "        closest_tip[ct] = tip_hit\n",
    "    #     print(np.argmin(ep_pts_dists), ep_found, eps_nm[np.argmin(ep_pts_dists)]/[4,4,40], eps_nm[j]/[4,4,40], center/[4,4,40])\n",
    "        dists_defects[ct] = min_dist\n",
    "        # print(dists_defects)\n",
    "        # print()\n",
    "        sizes[ct] = len(lens[ct])\n",
    "        ct+=1\n",
    "\n",
    "        \n",
    "    dists_defects_sub = dists_defects[dists_defects < error_distance_threshold_defects]\n",
    "    sizes_sub = sizes[dists_defects < error_distance_threshold_defects]\n",
    "\n",
    "    centers_sub = centers[dists_defects < error_distance_threshold_defects]\n",
    "    # print(centers_sub)\n",
    "    # print()\n",
    "\n",
    "    tips_hit_sub = closest_tip[dists_defects < error_distance_threshold_defects]\n",
    "    closest_skel_pts_sub = closest_skel_pts[dists_defects < error_distance_threshold_defects]\n",
    "    inds_sub = np.arange(centers.shape[0])[dists_defects < error_distance_threshold_defects]\n",
    "\n",
    "\n",
    "    # Also ranking each component based on its PCA- if the first component is big enough, the points are mostly linear\n",
    "    # These point sets seem to be less likely to be true errors\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca_vec = np.zeros(inds_sub.shape[0])\n",
    "    for i in range(inds_sub.shape[0]):\n",
    "        pca = PCA()#n_components=2)\n",
    "        pca.fit(mesh_obj.vertices[lens[inds_sub[i]]])\n",
    "\n",
    "        pca_vec[i] = pca.explained_variance_ratio_[0]\n",
    "\n",
    "    # dists_defects_sub[dists_defects_sub < 4000] = 100\n",
    "    dists_defects_norm = dists_defects_sub #/ np.max(dists_defects_sub)\n",
    "    ranks_ep = sizes_sub / dists_defects_norm * (1-pca_vec)\n",
    "    # ranks = sizes_sub**2 * (1-pca_vec)\n",
    "\n",
    "    #ranks_ep_errors_filt = ranks_ep[ranks_ep > .1]\n",
    "    #this will overreport errors\n",
    "\n",
    "    # centers_ep_thresholded = centers_sub[ranks_ep < ranks_threshold]\n",
    "    # centers_thresholded = centers_sub[ranks < ranks_threshold]\n",
    "\n",
    "\n",
    "    #top 20 what???\n",
    "    centers_ep_send_errors = centers_sub[np.argsort(ranks_ep)][::-1][:20]\n",
    "\n",
    "    # print(centers_ep_send_errors)\n",
    "    # print()\n",
    "    \n",
    "    final_mask_eps = np.full(centers_ep_send_errors.shape[0], True)\n",
    "    tips_hit_send_ep = tips_hit_sub[np.argsort(ranks_ep)][::-1][:20]\n",
    "    uns, nums = np.unique(tips_hit_send_ep, return_counts=True)\n",
    "\n",
    "    for un, num in zip(uns, nums):\n",
    "        if num > 1:\n",
    "            final_mask_eps[np.argwhere(tips_hit_send_ep == un)[1:]] = False\n",
    "\n",
    "    # Centers_errors_ep are the error locations, ranked by how close they are to an endpoint\n",
    "    centers_errors_ep = centers_ep_send_errors[final_mask_eps]\n",
    "    print(centers_errors_ep)\n",
    "    # This one doesn't care if we are close to an endpoint\n",
    "    # centers_errors = centers_sub[np.argsort(ranks)[::-1]][:20]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up renderer\n",
      "done setting up\n",
      "actors added\n",
      "camera set\n",
      "render done\n",
      "finalizing..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<vtkmodules.vtkRenderingOpenGL2.vtkOpenGLRenderer(0x7fec58008a00) at 0x7feca14450a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# centers_errors_ep is output of jagged errors merged with skel endpoints\n",
    "# centers is output of jagged errors\n",
    "# facets_send_final is output of flat errors merged with skel endpoints\n",
    "# mean_locs is the output of flat errors\n",
    "# eps_nm is the skel endpoints\n",
    "\n",
    "#VISUALZING HERE\n",
    "# syn_actor2 purple \n",
    "# mesh object is gray\n",
    "# syn_actor = trimesh_vtk.point_cloud_actor(eps_nm, size=100, color=(0.0, 0.0, 0.9))\n",
    "# syn_actor2 = trimesh_vtk.point_cloud_actor(centers, size=100, color=(0.9, 0.2, 0.9))\n",
    "# mesh_actor = trimesh_vtk.mesh_actor(mesh_obj, opacity=1, color=(0.7, 0.7, 0.7))\n",
    "# trimesh_vtk.render_actors([mesh_actor, skel_actor, syn_actor2, syn_actor])\n",
    "\n",
    "#VISUALZING HERE \n",
    "#also visualize facets_send_final\n",
    "# syn_actor = trimesh_vtk.point_cloud_actor(eps_nm, size=100, color=(0.0, 0.0, 0.9))\n",
    "#these will become errors_tips_send\n",
    "# purple point shoudl center_errors_ep\n",
    "\n",
    "\n",
    "# syn_actor4 = trimesh_vtk.point_cloud_actor(mean_locs, opacity = 0.75, size=200, color=(0.9, 0.2, 0.9))\n",
    "# #syn_actor = trimesh_vtk.point_cloud_actor(eps_nm, opacity = 0.75, size=200, color=(0.9, 0.2, 0.9))\n",
    "# # unscaled_facets_send_final = facets_send_final * [4,4,40]\n",
    "# # #PURPLE\n",
    "# syn_actor2 = trimesh_vtk.point_cloud_actor(centers_errors_ep, size=800, color=(0.9, 0.2, 0.9))\n",
    "# # #GREEN\n",
    "# syn_actor3 = trimesh_vtk.point_cloud_actor(unscaled_facets_send_final, size=800, color=(0.0, 0.9, 0.0))\n",
    "# #GRAY\n",
    "mesh_actor = trimesh_vtk.mesh_actor(mesh_obj, opacity=1, color=(0.7, 0.7, 0.7))\n",
    "#SKEL = PINK\n",
    "trimesh_vtk.render_actors([mesh_actor, skel_actor])\n",
    "\n",
    "\n",
    "# endpoints_gen = facets_send_final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[350628.6 , 143806.95,  15044.4 ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facets_send_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together = np.vstack((facets_send_final, centers_errors_ep/[4,4,40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[[ 79205.5212766  109247.69680851  20433.525     ]\n",
      " [ 79237.725      109174.275       20431.425     ]\n",
      " [ 78876.8121547  109878.64226519  20433.525     ]\n",
      " [ 78943.83       109722.48        20400.45      ]\n",
      " [ 79160.25       109597.5         20400.45      ]\n",
      " [ 79132.265625   109474.3125      20411.475     ]\n",
      " [ 79171.3125     109155.375       20400.45      ]\n",
      " [ 79382.91666667 109016.83333333  20433.525     ]\n",
      " [ 78681.75       110607.          20423.55      ]\n",
      " [ 78684.08333333 110589.5         20433.525     ]\n",
      " [ 78709.75       110495.          20420.4       ]\n",
      " [ 78662.5        110590.08333333  20419.35      ]\n",
      " [ 78716.75       110544.875       20409.375     ]\n",
      " [ 78608.25       110763.          20415.675     ]\n",
      " [ 78516.75       110943.          20410.425     ]\n",
      " [ 78425.93442623 111322.75        20400.45      ]\n",
      " [ 78404.52717391 111299.08695652  20408.325     ]\n",
      " [ 79759.43181818 109328.38636364  20413.69431818]]\n",
      "\n",
      "[[401602, 224623, 23991], [405273, 226312, 23618], [409204, 219553, 23892]]\n"
     ]
    }
   ],
   "source": [
    "real = [[401602, 224623, 23991],[405273, 226312, 23618],[409204, 219553, 23892]]\n",
    "acc = pred_eps_acc(real, together, 300)\n",
    "print(acc)\n",
    "print(together)\n",
    "print()\n",
    "print(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (3121358080.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [129], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    dist = math.sqrt((point[0]-other_point[0])**2) + (point[1] - other_point[1])**2 + (point[2]-other_point[2])**2)\u001b[0m\n\u001b[0m                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for point in real: \n",
    "    for other_point in together: \n",
    "        dist = math.sqrt((point[0]-other_point[0])**2) + (point[1] - other_point[1])**2 + (point[2]-other_point[2])**2)\n",
    "        print(dist)\n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAD AND GOOD PROCESS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "###PROCESS THAT it DOESN'T DO WELL ON\n",
    "Image('/Users/sheeltanna/Desktop/AGT_REPO/campfire/Small_Orphan_Image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "###PROCESS THAT it DOESN'T DO WELL ON\n",
    "Image('/Users/sheeltanna/Desktop/AGT_REPO/campfire/Screen Shot 2023-04-05 at 11.10.49 PM.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the predicted endpoints \n",
    "sorted_encapsulated_send, facets_send_final, errors_send, errors_tips_send, dummy, dummy2, dummy3 = error_locs_defects(864691135909994000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facets_send_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the accuracy + seeing the predicted vs real endpoints\n",
    "together = np.vstack((facets_send_final, errors_tips_send))\n",
    "    #should alter \"together\" if not set together equal to this line\n",
    "    # print(together)\n",
    "    # new = together[together != [0,0,0]]\n",
    "mask=np.sum(together,axis=1)\n",
    "together = together[mask > 0]\n",
    "print(\"predicted\")\n",
    "print(together)\n",
    "print()\n",
    "print(\"real\")\n",
    "print(orphans[\"real_endpoints\"][1])\n",
    "print()\n",
    "print(\"accurcy\")\n",
    "acc = pred_eps_acc(orphans[\"real_endpoints\"][1], together, 200)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before scaling of endpoints\")\n",
    "print(eps_nm)\n",
    "print()\n",
    "print(\"after scaling of endpoints\")\n",
    "print(facets_send_final)\n",
    "print()\n",
    "print(\"before scaling of errors\")\n",
    "print(centers)\n",
    "print()\n",
    "print(\"after scaling of errors\")\n",
    "print(errors_tips_send)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Hyperparams now\n",
    "observe changes on handful of orphans (visualize mesh)\n",
    "one notebook, clean calls, display figure\n",
    "have all of our updated params \n",
    "break down the endpoints we do find \n",
    "show example of orphan \n",
    "matplotlib + images+ illustrator etc \n",
    "\n",
    "DUE: END OF SEMESTER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
